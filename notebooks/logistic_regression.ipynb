{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Logistic Regression\n",
    "\n",
    "In this notebook, we will use logistic regression to perform a sentiment analysis on tweets. \n",
    "\n",
    "Given a tweet, we will decide if it has a positive sentiment or a negative one.\n",
    "\n",
    "We will implement logistic regression from scratch. For this notebook to work correctly, you will need to have assignment 2 completed. This requires you to implement the `logistic_regression` and `features` module of our `htwgnlp` package.\n",
    "\n",
    "Remember that you can find your tasks by searching for `TODO ASSIGNMENT-2` in your IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will use the Twitter dataset from `nltk`.\n",
    "\n",
    "It contains 10,000 tweets with positive and negative sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_tweets = twitter_samples.strings(\"positive_tweets.json\")\n",
    "negative_tweets = twitter_samples.strings(\"negative_tweets.json\")\n",
    "n_samples = len(postive_tweets) + len(negative_tweets)\n",
    "n_pos = len(postive_tweets)\n",
    "n_neg = len(negative_tweets)\n",
    "\n",
    "print(\"Total number of tweets: \", n_samples)\n",
    "print(\"Number of positive tweets: \", n_pos)\n",
    "print(\"Number of negative tweets: \", n_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we do a simple 80/20 train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data 80/20\n",
    "n_train = int(n_samples * 0.8)\n",
    "n_test = n_samples - n_train\n",
    "\n",
    "print(\"Number of training samples: \", n_train)\n",
    "print(\"Number of test samples: \", n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that the classes in the dataset are balanced, we want both the training and test set to contain 50% of the positive and 50% of the negative tweets.\n",
    "\n",
    "That means, in our case, the training set should contain 4000 tweets of each class, while the test set should contain 1000 tweets of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(n_train / 2)\n",
    "\n",
    "# training data\n",
    "train_data_pos = postive_tweets[:n]\n",
    "train_data_neg = negative_tweets[:n]\n",
    "print(f\"train_data_pos: {len(train_data_pos)}\")\n",
    "print(f\"train_data_neg: {len(train_data_neg)}\")\n",
    "\n",
    "# test data\n",
    "test_data_pos = postive_tweets[n:]\n",
    "test_data_neg = negative_tweets[n:]\n",
    "print(f\"test_data_pos: {len(test_data_pos)}\")\n",
    "print(f\"test_data_neg: {len(test_data_neg)}\")\n",
    "\n",
    "# build train and test datasets\n",
    "train_data = train_data_pos + train_data_neg\n",
    "test_data = test_data_pos + test_data_neg\n",
    "print(f\"train_data: {len(train_data)}\")\n",
    "print(f\"test_data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the labels, we create a numpy array that holds the sentiment labels (0 for negative and 1 for positive).\n",
    "\n",
    "The label arrays should be of shape (n_samples, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "y_train = np.append(\n",
    "    np.ones((len(train_data_pos), 1)), np.zeros((len(train_data_neg), 1)), axis=0\n",
    ")\n",
    "y_test = np.append(\n",
    "    np.ones((len(test_data_pos), 1)), np.zeros((len(test_data_neg), 1)), axis=0\n",
    ")\n",
    "\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "For the preprocessing, we will use the `TweetProcessor` class from the previous exercise. It is located in the `preprocessing` module of our `htwgnlp` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htwgnlp.preprocessing import TweetProcessor\n",
    "\n",
    "processor = TweetProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next step, feature extraction, we need the training samples in a preprocessed form.\n",
    "\n",
    "The preprocessing of the whole training set may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed = [processor.process_tweet(tweet) for tweet in train_data]\n",
    "train_data_processed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequencies\n",
    "\n",
    "As the features for our sentiment analysis, we will use the frequencies of positive and negative words in each tweet.\n",
    "\n",
    "Together with the bias term, we will have a feature vector of length 3 for each tweet:\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = \\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    n_{pos} \\\\\n",
    "    n_{neg} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htwgnlp.features import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the dictionary of word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.build_word_frequencies(train_data_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.word_frequencies[\"happi\", 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a specific example:\n",
    "\n",
    "The **raw tweet** looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the **preprocessing**, we get the tweet in its **tokenized form**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = processor.process_tweet(train_data[0])\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_features` function gives us the **numeric representation** of the tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_features(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that\n",
    "- the first element in the tuple is the bias term, \n",
    "- the second element corresponds to the frequency of words in the positive class, and\n",
    "- the third element holds the frequency of words in the negative class.\n",
    "\n",
    "Here is another way that can help you to interpret the feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tweet:\n",
    "    print(\n",
    "        f\"number of times the word {token:<15} appeared in tweets labeled as positive: {vectorizer.word_frequencies[(token, 1)]:<4} as negative: {vectorizer.word_frequencies[(token, 0)]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "To make sure that every sample runs through the same processing, we encapsulate the preprocessing and feature extraction in a `tweet_pipeline` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_pipeline(tweet):\n",
    "    tweet = processor.process_tweet(tweet)\n",
    "    return vectorizer.get_features(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We will use our own implementation of logistic regression provided in the `logistic_regression` module of our `htwgnlp` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htwgnlp.logistic_regression import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the features that we need for the training, we need to run the `tweet_pipeline` function from above on all training samples.\n",
    "\n",
    "This gives us the feature matrix `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((n_train, 3))\n",
    "for i in range(n_train):\n",
    "    X_train[i, :] = tweet_pipeline(train_data[i])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, together with the label vector `y_train`, we have all required input variables ready to train our logistic regression model.\n",
    "\n",
    "We can do so by calling the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, cost = model.fit(X_train, y_train)\n",
    "print(f\"theta:\\n{theta}\")\n",
    "print(f\"cost:\\n{cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented the assignment correctly, the returned values for the `cost` and the weights `theta` should be:\n",
    "\n",
    "```python\n",
    "theta:\n",
    "[[ 6.03443427e-08]\n",
    " [ 5.38196083e-04]\n",
    " [-5.58301889e-04]]\n",
    "cost:\n",
    "[[0.2252131]]\n",
    "```\n",
    "\n",
    "> Note that depending on your preprocessing pipeline from the previous exercise, your results might differ slightly. This should be no problem, as long as the values are in the same order of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the model, we will use the test set that we created in the beginning. \n",
    "\n",
    "To obtain the test set features `X_test`, we need the same preprocessing steps as for the training set. We will reuse our simple `tweet_pipeline` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((n_test, 3))\n",
    "for i in range(n_test):\n",
    "    X_test[i, :] = tweet_pipeline(test_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the labels, we can use the `predict` method of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a single example. The prediction should be 1, which corresponds to a positive sentiment.\n",
    "\n",
    "```python\n",
    "# expected output\n",
    "tweet: @tillyyandtroye you're welcome :)\n",
    "prediction: [1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tweet: {test_data[111]}\")\n",
    "x_i = tweet_pipeline(test_data[111])\n",
    "print(f\"prediction: {model.predict(x_i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try it yourself and predict your own tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"Konstanz is a great place to live!\"\n",
    "x_i = tweet_pipeline(tweet)\n",
    "print(f\"prediction: {model.predict(x_i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We can calculate the accuracy of our model by comparing the predicted values to the test set values.\n",
    "\n",
    "There are many ways to do it. Here is an approach that uses element-wise comparison of two arrays. This will return an array of booleans, where each element is True if the predicted value is equal to the test set value at the same index, and False otherwise. \n",
    "\n",
    "Numpy then converts booleans to integers (True becomes 1, False becomes 0). That is why the mean of the array will be the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "(y_pred == y_test).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "We can find the error cases by checking the predicted labels against the test set labels.\n",
    "\n",
    "We can use `np.nonzero` to get the indices of the error cases. Using these indices, we can inspect the corresponding samples from the test set.\n",
    "\n",
    "> Note that `np.nonzero` should be preferred over `np.where`, as the [docs](https://numpy.org/doc/stable/reference/generated/numpy.where.html) say.\n",
    "> Also note that `np.nonzero` returns a tuple of arrays, which is why we need to access the first element of the tuple to get our indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cases = np.nonzero((y_pred.flatten() != y_test.flatten()))[0]\n",
    "error_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities for each class can be obtained with the `predict_prob` method. This is interesting if we want to know how confident the model is about its prediction, which can be useful for error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_prob(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can take a look at the error samples.\n",
    "\n",
    "What can you notice about the error cases and why do you think the misclassifications happened? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in error_cases:\n",
    "    print(\n",
    "        f\"sample: {i:>4}, predicted class: {y_pred[i]}, actual class: {y_test[i]} probability: {y_prob[i].item():7.4f}, tweet: {test_data[i]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Word Frequencies\n",
    "\n",
    "To get a better understanding of the model, we can also visualize the word frequencies for the positive and negative class.\n",
    "\n",
    "The following code snippet visualizes some selected words along with their positive and negative frequencies in the corpus.\n",
    "\n",
    "> Don't worry if the plotting code is not clear to you. It is not important for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select some words to appear in the report\n",
    "keys = [\n",
    "    \"happi\",\n",
    "    \"merri\",\n",
    "    \"nice\",\n",
    "    \"good\",\n",
    "    \"bad\",\n",
    "    \"sad\",\n",
    "    \"mad\",\n",
    "    \"best\",\n",
    "    \"pretti\",\n",
    "    \"‚ù§\",\n",
    "    \":)\",\n",
    "    \":(\",\n",
    "    \"üòí\",\n",
    "    \"üò¨\",\n",
    "    \"üòÑ\",\n",
    "    \"üòç\",\n",
    "    \"song\",\n",
    "    \"idea\",\n",
    "    \"power\",\n",
    "    \"play\",\n",
    "    \"magnific\",\n",
    "]\n",
    "\n",
    "# prepare the data for the plot: [<word>, <positive_count>, <negative_count>]\n",
    "data = [\n",
    "    [\n",
    "        word,\n",
    "        vectorizer.word_frequencies[(word, 1)],\n",
    "        vectorizer.word_frequencies[(word, 0)],\n",
    "    ]\n",
    "    for word in keys\n",
    "]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# convert positive and negative raw counts to logarithmic scale. we add 1 to avoid log(0)\n",
    "x = np.log([x[1] + 1 for x in data])\n",
    "y = np.log([x[2] + 1 for x in data])\n",
    "\n",
    "# Plot a dot for each pair of words\n",
    "ax.scatter(x, y)\n",
    "\n",
    "# assign axis labels\n",
    "plt.xlabel(\"Log Positive count\")\n",
    "plt.ylabel(\"Log Negative count\")\n",
    "\n",
    "# Add the word as the label at the same position as you added the points just before\n",
    "for i in range(0, len(data)):\n",
    "    ax.annotate(data[i][0], (x[i], y[i]), fontsize=12)\n",
    "\n",
    "ax.plot([0, 9], [0, 9], color=\"red\")  # Plot the red line that divides the 2 areas.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use logistic regression for sentiment analysis.\n",
    "\n",
    "With a simple classifier like this, we can already achieve an accuracy of over 99%.\n",
    "\n",
    "But keep in mind that the `nltk` tweet dataset, while being a good starting point, is not a good representation of real-world data.\n",
    "\n",
    "Also we are working in a lab environment, and the primary goal of this notebook is not efficiency, but to demonstrate the concepts of logistic regression in a understandable way.\n",
    "\n",
    "For a production scenario, what parts of the code do you think should be improved?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
