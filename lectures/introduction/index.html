
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A practical course on natural language processing @ HTWG Konstanz.">
      
      
      
      
        <link rel="prev" href="../preface/">
      
      
        <link rel="next" href="../preprocessing/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Introduction - Practical NLP</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction-to-natural-language-processing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Practical NLP" class="md-header__button md-logo" aria-label="Practical NLP" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Practical NLP
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introduction
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/pkeilbach/htwg-practical-nlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    pkeilbach/htwg-practical-nlp
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Welcome

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../course_profile/" class="md-tabs__link">
        
  
  
    
  
  About

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../getting_started/" class="md-tabs__link">
        
  
  
    
  
  Getting Started

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../preface/" class="md-tabs__link">
          
  
  
    
  
  Lectures

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../assignments/" class="md-tabs__link">
        
  
  
    
  
  Assignments

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../presentations/" class="md-tabs__link">
        
  
  
    
  
  Presentations

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../faq/" class="md-tabs__link">
        
  
  
    
  
  FAQ

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../exam/" class="md-tabs__link">
        
  
  
    
  
  Exam

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Practical NLP" class="md-nav__button md-logo" aria-label="Practical NLP" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Practical NLP
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pkeilbach/htwg-practical-nlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    pkeilbach/htwg-practical-nlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Welcome
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course_profile/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Lectures
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Lectures
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../preface/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Preface
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#nlp-in-our-everyday-lives" class="md-nav__link">
    <span class="md-ellipsis">
      NLP in our everyday lives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a-brief-history-about-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      A brief history about NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tasks-that-can-be-solved-by-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Tasks that can be solved by NLP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tasks that can be solved by NLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sentiment-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sentiment analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#machine-translation" class="md-nav__link">
    <span class="md-ellipsis">
      Machine translation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named-entity-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      Named entity recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-of-speech-pos-tagging" class="md-nav__link">
    <span class="md-ellipsis">
      Part-of-speech (POS) tagging
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#topic-modelling" class="md-nav__link">
    <span class="md-ellipsis">
      Topic modelling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      Information Retrieval
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Summarization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#question-answering" class="md-nav__link">
    <span class="md-ellipsis">
      Question Answering
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-blocks-of-language" class="md-nav__link">
    <span class="md-ellipsis">
      Building Blocks of Language
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building Blocks of Language">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#phonemes" class="md-nav__link">
    <span class="md-ellipsis">
      Phonemes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#morphemes-and-lexemes" class="md-nav__link">
    <span class="md-ellipsis">
      Morphemes and Lexemes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#syntax" class="md-nav__link">
    <span class="md-ellipsis">
      Syntax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context" class="md-nav__link">
    <span class="md-ellipsis">
      Context
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenges-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Challenges in NLP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Challenges in NLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ambiguity" class="md-nav__link">
    <span class="md-ellipsis">
      Ambiguity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#world-knowledge" class="md-nav__link">
    <span class="md-ellipsis">
      World Knowledge
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creativity" class="md-nav__link">
    <span class="md-ellipsis">
      Creativity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diversity" class="md-nav__link">
    <span class="md-ellipsis">
      Diversity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nlp-in-the-era-of-artificial-intelligence" class="md-nav__link">
    <span class="md-ellipsis">
      NLP in the era of Artificial Intelligence
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NLP in the era of Artificial Intelligence">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rule-based-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Rule-based NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#machine-learning-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Machine Learning for NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-learning-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Learning for NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limitations-of-ai-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations of AI in NLP
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../preprocessing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Preprocessing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../feature_extraction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Feature Extraction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../logistic_regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logistic Regression
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../naive_bayes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Naive Bayes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vector_space_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vector Space Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minimum_edit_distance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Minimum Edit Distance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../language_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../word_embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Word Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sequence_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sequence Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../attention_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../further_reading/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Where to go from here?
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignments
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../presentations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Presentations
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAQ
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../exam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Exam
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#nlp-in-our-everyday-lives" class="md-nav__link">
    <span class="md-ellipsis">
      NLP in our everyday lives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a-brief-history-about-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      A brief history about NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tasks-that-can-be-solved-by-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Tasks that can be solved by NLP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tasks that can be solved by NLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sentiment-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sentiment analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#machine-translation" class="md-nav__link">
    <span class="md-ellipsis">
      Machine translation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named-entity-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      Named entity recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-of-speech-pos-tagging" class="md-nav__link">
    <span class="md-ellipsis">
      Part-of-speech (POS) tagging
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#topic-modelling" class="md-nav__link">
    <span class="md-ellipsis">
      Topic modelling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      Information Retrieval
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Summarization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#question-answering" class="md-nav__link">
    <span class="md-ellipsis">
      Question Answering
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-blocks-of-language" class="md-nav__link">
    <span class="md-ellipsis">
      Building Blocks of Language
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building Blocks of Language">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#phonemes" class="md-nav__link">
    <span class="md-ellipsis">
      Phonemes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#morphemes-and-lexemes" class="md-nav__link">
    <span class="md-ellipsis">
      Morphemes and Lexemes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#syntax" class="md-nav__link">
    <span class="md-ellipsis">
      Syntax
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#context" class="md-nav__link">
    <span class="md-ellipsis">
      Context
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenges-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Challenges in NLP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Challenges in NLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ambiguity" class="md-nav__link">
    <span class="md-ellipsis">
      Ambiguity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#world-knowledge" class="md-nav__link">
    <span class="md-ellipsis">
      World Knowledge
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creativity" class="md-nav__link">
    <span class="md-ellipsis">
      Creativity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#diversity" class="md-nav__link">
    <span class="md-ellipsis">
      Diversity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nlp-in-the-era-of-artificial-intelligence" class="md-nav__link">
    <span class="md-ellipsis">
      NLP in the era of Artificial Intelligence
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NLP in the era of Artificial Intelligence">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rule-based-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Rule-based NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#machine-learning-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Machine Learning for NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-learning-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Learning for NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#limitations-of-ai-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations of AI in NLP
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key Takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="introduction-to-natural-language-processing">Introduction to Natural Language Processing<a class="headerlink" href="#introduction-to-natural-language-processing" title="Permanent link">&para;</a></h1>
<p>The first lecture will give you a basic understanding of what Natural Language Processing (<abbr title="Natural Language Processing">NLP</abbr>) is about, the problems we deal with and the challenges that come with it.
The goal is to get a good intuition of what it means to work with language from a programmatic perspective.</p>
<div class="admonition quote">
<p class="admonition-title">Natural Language Processing</p>
<p>Natural Language Processing (<abbr title="Natural Language Processing">NLP</abbr>) is a branch of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language.
By combining computational linguistics with machine learning and deep learning, <abbr title="Natural Language Processing">NLP</abbr> allows machines to process and analyze vast amounts of natural language data.
This capability is fundamental for applications such as speech recognition, text analysis, and language translation.<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
</div>
<h2 id="nlp-in-our-everyday-lives"><abbr title="Natural Language Processing">NLP</abbr> in our everyday lives<a class="headerlink" href="#nlp-in-our-everyday-lives" title="Permanent link">&para;</a></h2>
<p>In our daily digital lives, we interact with a lot of apps and tools that are based on <abbr title="Natural Language Processing">NLP</abbr> technologies.
The following figure gives an overview of real-world <abbr title="Natural Language Processing">NLP</abbr> applications along with popular examples<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>.</p>
<p><img alt="An overview of real-world NLP applications with popular examples" src="../../img/nlp-real-world-applications.drawio.svg" title="Real-world NLP applications" /></p>
<ul>
<li><strong>Voice-based assistants</strong> like <a href="https://www.amazon.com/how-does-alexa-work/b?ie=UTF8&amp;node=21166405011">Alexa</a> or <a href="https://machinelearning.apple.com/research/hey-siri">Siri</a> utilize a variety of <abbr title="Natural Language Processing">NLP</abbr> techniques to interact with its users, i.e. they need to understand user commands and questions, and reply accordingly using Text-to-Speech (TTS).</li>
<li>Modern <strong>search engines</strong> like <a href="https://www.google.com/search/howsearchworks/">Google</a> or <a href="https://support.microsoft.com/en-us/topic/how-bing-delivers-search-results-d18fc815-ac37-4723-bc67-9229ce3eb6a3">Bing</a> make heavy use of <abbr title="Natural Language Processing">NLP</abbr> for a variety of subtasks, such as understanding the user query, autocompletion, or ranking and grouping the query results.</li>
<li><strong>Social media platforms</strong> make use of <abbr title="Natural Language Processing">NLP</abbr>, e.g. to analyse user comments, or make suggestions to their users.
  Also platforms like Youtube or conference tools are able to automatically create transcriptions on the fly using "Speech-to-text" (SST) technologies.</li>
<li>In popular <strong>email applications</strong> like Gmail or Outlook, <abbr title="Natural Language Processing">NLP</abbr> is used for tasks like spam filtering, <a href="https://patents.google.com/patent/US8832205B2/en">calendar event extraction</a> or <a href="https://blog.google/products/gmail/save-time-with-smart-reply-in-gmail/">smart replies</a>.</li>
<li><strong>Text processing apps</strong> offer auto-correction or auto-completion features to their users, i.e. spell-checking or grammar correction.
  <a href="https://www.grammarly.com/blog/how-does-grammarly-work/">Grammarly</a> is a nice example here, as well as any smartphone keyboard.</li>
<li>More and more companies offer <strong>chatbots</strong> (aka conversational agents) on their websites for their clients.
  With <a href="https://openai.com/blog/chatgpt/">ChatGPT</a>, <strong>conversational agents</strong> (and <abbr title="Natural Language Processing">NLP</abbr> in general) reached a new level just recently.</li>
</ul>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>Based on your <strong>working experience</strong>, where have you already encountered, or can think of, potential <strong><abbr title="Natural Language Processing">NLP</abbr> applications</strong>?</p>
</div>
<h2 id="a-brief-history-about-nlp">A brief history about <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#a-brief-history-about-nlp" title="Permanent link">&para;</a></h2>
<p>IMHO, every lecture should provide a little historical background in the beginning<sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup>: üìú</p>
<ul>
<li>
<p><strong>1950s‚Äì1990s</strong>
  Initial attempts are made to map hard rules around languages and follow logical steps to accomplish tasks like translating a sentence from one language to another.
  While this works sometimes, strictly defined rules only work for concrete, well-defined tasks that the system has knowledge about.</p>
<div class="admonition info">
<p class="admonition-title">Noam Chomsky</p>
<p>Renowned linguist and cognitive scientist <a href="https://en.wikipedia.org/wiki/Noam_Chomsky">Noam Chomsky</a> introduced the theory of generative grammar, which revolutionized the understanding of language structure and acquisition. His work laid the theoretical groundwork for studying language processing and understanding the innate structures that govern language use. Chomsky's theories on syntax and the nature of language have influenced computational linguistics and the development of algorithms for natural language processing, informing how machines understand and generate human language. His critiques of AI's ability to fully understand language have also sparked important discussions on the limitations of current language models.</p>
</div>
</li>
<li>
<p><strong>1990s</strong>
  Language models begin evolving into statistical models and language patterns start being analyzed, but larger-scale projects are limited by computing power.</p>
</li>
<li>
<p><strong>2000s</strong>
  Advancements in machine learning increase the complexity of language models, and the wide adoption of the internet sees an enormous increase in available training data.</p>
<div class="admonition info">
<p class="admonition-title">Geoffrey Hinton</p>
<p>Often referred to as one of the "Godfathers of Deep Learning," <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton">Geoffrey Hinton</a> has made significant contributions to the field of neural networks and deep learning, which are foundational to modern language models. His work on backpropagation, neural networks, and the development of the dropout technique has greatly influenced the training of deep learning models. Hinton's research laid the groundwork for the advancement of architectures like BERT and GPT, significantly impacting <abbr title="Natural Language Processing">NLP</abbr> and machine learning as a whole.</p>
<p>Together with <a href="https://en.wikipedia.org/wiki/John_Hopfield">John Hopfield</a>, he was awarded the 2024 Nobel Prize in Physics.</p>
</div>
</li>
<li>
<p><strong>2012</strong>
  Advancements in deep learning architectures and larger data sets lead to the development of GPT (Generative Pre-trained Transformer).</p>
</li>
<li>
<p><strong>2018</strong>
  Google introduces BERT (Bidirectional Encoder Representations from Transformers), which is a big leap in architecture and paves the way for future large language models.</p>
</li>
<li>
<p><strong>2020</strong>
  OpenAI releases GPT-3, which becomes the largest model at 175B parameters and sets a new performance benchmark for language-related tasks.</p>
<div class="admonition info">
<p class="admonition-title">Ilya Sutskever</p>
<p>Co-founder and Chief Scientist at OpenAI, <a href="https://en.wikipedia.org/wiki/Ilya_Sutskever">Ilya Sutskever</a> has played a pivotal role in the development of groundbreaking language models, including GPT-2 and GPT-3. His work in deep learning and reinforcement learning has advanced the understanding and capabilities of generative models. Sutskever's contributions to the architecture and training of these models have led to significant improvements in their performance on a wide range of language-related tasks. His leadership at OpenAI has also driven the broader adoption and awareness of large language models and their potential applications.</p>
</div>
</li>
<li>
<p><strong>2022</strong>
  ChatGPT is launched, which turns GPT-3 and similar models into a service that is widely accessible to users through a web interface and kicks off a huge increase in public awareness of LLMs and generative AI.</p>
</li>
<li>
<p><strong>2023</strong>
  Open source LLMs begin showing increasingly impressive results with releases such as Dolly 2.0, LLaMA, Alpaca, and Vicuna. GPT-4 is also released, setting a new benchmark for both parameter size and performance.</p>
</li>
</ul>
<h2 id="tasks-that-can-be-solved-by-nlp">Tasks that can be solved by <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#tasks-that-can-be-solved-by-nlp" title="Permanent link">&para;</a></h2>
<!-- TODO EXAM -->

<p><abbr title="Natural Language Processing">NLP</abbr> is used for a wide variety of language-related tasks, including answering questions, classifying text in a variety of ways, and conversing with users.</p>
<p>If you design an <abbr title="Natural Language Processing">NLP</abbr> system, you may make use of multiple tasks.</p>
<p>Here are some tasks that can be solved by <abbr title="Natural Language Processing">NLP</abbr><sup id="fnref:4"><a class="footnote-ref" href="#fn:4">4</a></sup>:</p>
<h3 id="sentiment-analysis">Sentiment analysis<a class="headerlink" href="#sentiment-analysis" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Sentiment analysis</strong> is a <strong>text classification</strong> problem and it classifies the emotional intent of text.</li>
<li><strong>Input</strong> is a text, and the <strong>output</strong> is the probability of the sentiment being positive, negative, or neutral.</li>
<li><strong>Features</strong> used may include hand-generated features, word n-grams, <abbr title="Term Frequency-Inverse Document Frequency">TF-IDF</abbr>, or deep learning models for capturing text dependencies.</li>
<li>Common <strong>applications</strong> include classifying customer reviews and identifying signs of mental illness in online comments.</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Here is a fictional example of customer reviews of a hotel booking service:</p>
<ul>
<li>üòÉ Great service for an affordable price. We will definitely be booking again!</li>
<li>üòê Just booked two nights at this hotel.</li>
<li>üò° Horrible service. The room was dirty and unpleasant. Not worth the money.</li>
</ul>
<p>Email spam detection is another typical example of a binary text classification problem in <abbr title="Natural Language Processing">NLP</abbr>.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Toxicity classification</p>
<p>Toxicity classification, a branch of sentiment analysis, categorizes hostile content like threats, insults, obscenities, and hate speech. It's used to moderate online conversations by detecting and silencing offensive comments or scanning for defamation.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Text classification with Naive Bayes</p>
<p>A very good starting algorithm for text classification tasks in <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier"><strong>Naive Bayes</strong></a> algorithm.
This is primarily because it is relatively simple to understand and implement, and very fast to train and run.
We will cover the <strong>Naive Bayes algorithm</strong> later in the course, as well as in one of the assignments.</p>
</div>
<h3 id="machine-translation">Machine translation<a class="headerlink" href="#machine-translation" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Machine translation</strong> automates the process of <strong>translating</strong> text between different languages.</li>
<li>The <strong>input</strong> is text in a source language, and the <strong>output</strong> is text in a target language.</li>
<li>Machine translation improves communication on platforms like Facebook and Skype.</li>
<li>Effective models can distinguish between words with similar meanings.</li>
<li>Some systems also identify the language of the input text.</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<ul>
<li><a href="https://www.deepl.com">DeepL</a> is a well-known example of this application.</li>
</ul>
</div>
<h3 id="named-entity-recognition">Named entity recognition<a class="headerlink" href="#named-entity-recognition" title="Permanent link">&para;</a></h3>
<ul>
<li><strong><abbr title="Named Entity Recognition">NER</abbr></strong> extracts <strong>entities</strong> from text and classifies them into predefined categories (e.g., names, persons, organizations, locations, quantities, book title, etc.).</li>
<li>The <strong>input</strong> is text, and the <strong>output</strong> includes the identified entities and their positions in the text.</li>
<li><abbr title="Named Entity Recognition">NER</abbr> is valuable for <strong>applications</strong> like summarizing news articles and fighting disinformation.</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>The <a href="https://spacy.io/">spaCy library</a> is an open-source Python library for advanced Natural Language Processing that provides efficient tools for tasks such as tokenization, <abbr title="part of speech">POS</abbr> tagging, <abbr title="Named Entity Recognition">NER</abbr>, and dependency parsing.</p>
<p>Here is an <a href="https://spacy.io/usage/linguistic-features#named-entities">example</a> of <abbr title="Named Entity Recognition">NER</abbr> with spaCy</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">spacy</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;Apple is looking at buying U.K. startup for $1 billion&quot;</span><span class="p">)</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">start_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">end_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>Text</th>
<th>Start</th>
<th>End</th>
<th>Label</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Apple</td>
<td>0</td>
<td>5</td>
<td>ORG</td>
<td>Companies, agencies, institutions.</td>
</tr>
<tr>
<td>U.K.</td>
<td>27</td>
<td>31</td>
<td>GPE</td>
<td>Geopolitical entity, i.e. countries, cities, states.</td>
</tr>
<tr>
<td>$1 billion</td>
<td>44</td>
<td>54</td>
<td>MONEY</td>
<td>Monetary values, including unit.</td>
</tr>
</tbody>
</table>
<p>It can be visualized as follows:</p>
<p><img alt="NER with spaCy" src="../../img/intro-ner.png" /></p>
</div>
<h3 id="part-of-speech-pos-tagging">Part-of-speech (<abbr title="part of speech">POS</abbr>) tagging<a class="headerlink" href="#part-of-speech-pos-tagging" title="Permanent link">&para;</a></h3>
<ul>
<li>In <abbr title="Natural Language Processing">NLP</abbr>, the <strong>anatomy</strong> of a sentence is commonly described using <strong><abbr title="part of speech">POS</abbr> tags</strong>, which involves assigning <strong>grammatical categories</strong> (e.g., noun, verb, adjective) to each word in the sentence.</li>
<li>The <strong>input</strong> is a sequence of words, and the <strong>output</strong> is a tagged sequence indicating the <abbr title="part of speech">POS</abbr> for each word.</li>
<li><abbr title="part of speech">POS</abbr> tagging is essential for various <abbr title="Natural Language Processing">NLP</abbr> tasks, such as syntactic parsing, machine translation, and information retrieval.</li>
</ul>
<div class="admonition example">
<p class="admonition-title"><abbr title="part of speech">POS</abbr>-tagging with the Python spaCy library</p>
<p>Here is an <a href="https://spacy.io/usage/linguistic-features#pos-tagging">example</a> of <abbr title="part of speech">POS</abbr>-tagging with spaCy</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">spacy</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">spacy</span><span class="w"> </span><span class="kn">import</span> <span class="n">displacy</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;This is a sentence.&quot;</span><span class="p">)</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="n">displacy</span><span class="o">.</span><span class="n">serve</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;dep&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Output:</p>
<p><img alt="POS-tagging with spaCy" src="https://spacy.io/images/displacy.svg" /></p>
</div>
<div class="admonition info">
<p class="admonition-title"><abbr title="part of speech">POS</abbr>-tagsets</p>
<p>A tagset is a predefined list of grammatical categories used in Natural Language Processing to classify words during tasks like <abbr title="part of speech">POS</abbr> tagging.</p>
<p>A popular tagging convention is <a href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html">Penn Treebank tagset</a> which is also used by default by the Python <a href="https://www.nltk.org/api/nltk.tag.html">Natural Language Toolkit library</a>.</p>
<p>A simplified <a href="https://github.com/slavpetrov/universal-pos-tags">universal tagset</a> by Google Research maps the Penn Treebank tagset to only 12 tags.</p>
</div>
<h3 id="topic-modelling">Topic modelling<a class="headerlink" href="#topic-modelling" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Topic modeling</strong> is an <strong>unsupervised text mining</strong> task that identifies abstract topics in a collection of documents.</li>
<li>The <strong>input</strong> is a corpus of documents, and the <strong>output</strong> is a list of topics, with each topic consisting of relevant words and proportions assigned to documents.</li>
<li>Topic modeling has <strong>commercial applications</strong>, such as helping lawyers find evidence in legal documents.</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Latent Dirichlet Allocation</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation</a></strong> is a popular technique that views documents as mixtures of topics, and topics as mixtures of words.</p>
</div>
<h3 id="text-generation">Text generation<a class="headerlink" href="#text-generation" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Text generation</strong> (aka natural language generation) produces text that mimics human-written content.</li>
<li>Models can be <strong>fine-tuned</strong> to generate text in various formats, like <strong>tweets, blogs,</strong> and <strong>computer code</strong>.</li>
<li>Common applications include <strong>autocomplete</strong> and <strong>chatbots</strong>.</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Autocomplete</p>
<p><strong>Autocomplete</strong> predicts what word comes next, and autocomplete systems of varying complexity are used in chat applications like WhatsApp. Google uses autocomplete to predict search queries. One of the most famous models for autocomplete is GPT-2, which has been used to write articles, song lyrics, and much more.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Grammatical error correction</p>
<p>Grammatical error correction models use grammatical rules to fix text. This is typically approached as a sequence-to-sequence task, where the model learns to transform an ungrammatical sentence into a correct one. Tools like <a href="https://www.grammarly.com/">Grammarly</a> and Microsoft Word implement these models to enhance writing, while schools use them to grade student essays.</p>
</div>
<h3 id="information-retrieval">Information Retrieval<a class="headerlink" href="#information-retrieval" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Information retrieval</strong> aims to find the most relevant documents for a given <strong>query</strong>.</li>
<li>It is essential in <strong>search</strong> and <strong>recommendation systems</strong> and focuses on retrieving a relevant set of documents, not directly answering the query.</li>
<li>These systems handle massive collections of documents (millions), retrieving the most relevant ones.</li>
<li>Two main processes involved are <strong>indexing</strong> (typically done using vector space models and Two-Tower Networks) and <strong>matching</strong> (based on similarity or distance scores).</li>
<li>Advanced systems, such as Google's, use <strong>multimodal information retrieval</strong>, working across <strong>text, image, and video data</strong>.</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Elasticsearch</p>
<p>A popular example for an information retrieval system is <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Elasticsearch</a>. It is an open-source search and analytics engine built on top of <a href="https://lucene.apache.org/">Apache Lucene</a>. It is designed for fast, scalable search capabilities and is widely used for a variety of applications, including full-text search, structured data retrieval, and real-time analytics.</p>
</div>
<h3 id="summarization">Summarization<a class="headerlink" href="#summarization" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Summarization</strong> aims to shorten text while emphasizing the most relevant information.</li>
<li>Some summarizers are able to evaluate <strong>factual consistency</strong> for accurate <strong>output</strong>.</li>
<li><strong>Extractive summarization</strong>: Selects and combines the most important sentences from the <strong>input</strong> text.</li>
<li><strong>Abstractive summarization</strong>: Creates a summary by paraphrasing the <strong>input</strong> text, resulting in an <strong>output</strong> that may contain new words and sentences not present in the original. This is modeled as a sequence-to-sequence task.</li>
</ul>
<h3 id="question-answering">Question Answering<a class="headerlink" href="#question-answering" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Question answering</strong> involves providing answers to human-posed questions in <strong>natural language</strong>.</li>
<li>Notable example: <strong>Watson</strong> won the game show <strong>Jeopardy</strong> against human champions in 2011.</li>
<li><strong>Multiple choice</strong>: A question is paired with a set of possible answers, and the task is to select the <strong>correct answer</strong>.</li>
<li><strong>Open domain</strong>: The model answers questions in <strong>natural language</strong> without provided options, often by querying a large number of <strong>texts</strong>.</li>
</ul>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>In a modern <strong>email application</strong>, which of the above <strong><abbr title="Natural Language Processing">NLP</abbr> tasks</strong> could be utilized to achieve a great user experience?</p>
<details class="info">
<summary>Answer</summary>
<p>We can find many <abbr title="Natural Language Processing">NLP</abbr> tasks in a modern email client, such as:</p>
<ul>
<li>information extraction: suggest calendar events</li>
<li>spam classification: spam or not spam</li>
<li>summarization: a potential plugin for long and annoying emails</li>
<li>information retrieval: email search capabilities</li>
<li>text generation: suggest answers or sophisticated autocompletion</li>
<li>...</li>
</ul>
</details>
</div>
<h2 id="building-blocks-of-language">Building Blocks of Language<a class="headerlink" href="#building-blocks-of-language" title="Permanent link">&para;</a></h2>
<p>While linguistics is the systematic study of language, <abbr title="Natural Language Processing">NLP</abbr> tries to make language processable by computer systems.</p>
<p>To study <abbr title="Natural Language Processing">NLP</abbr>, we don't need to be linguistic experts, but it is important to understand some core linguistic concepts. In this section, we will dissect language into its building blocks.</p>
<p>For the scope of this course, we think of human language as composed of four major building blocks: phonemes, morphemes and lexemes, syntax, and context.
In linguistics, each of the building blocks described in this section is a research area for itself.</p>
<p><img alt="Building blocks of language as relevant for this course" src="../../img/language-building-blocks.drawio.svg" title="Building blocks of language as relevant for this course" /></p>
<h3 id="phonemes">Phonemes<a class="headerlink" href="#phonemes" title="Permanent link">&para;</a></h3>
<p>Description:</p>
<ul>
<li>Layer of <strong>speech and sound</strong></li>
<li>Smallest units of speech sound in a language</li>
<li>Vary across languages, i.e. each language has its own set of phonemes.</li>
<li>Standard English has <a href="https://en.wikipedia.org/wiki/Received_Pronunciation#Phonology">44 phonemes</a> (i.e. 24 consonant phonemes, and 20 vowel phonemes)</li>
<li>German: 46 phonemes</li>
<li>Spanish: 24 phonemes</li>
<li>Usually denoted in slashes using the symbols of the <a href="https://en.wikipedia.org/wiki/International_Phonetic_Alphabet">International Phonetic Alphabeth (IPA)</a></li>
<li>May or may not have a meaning by themselves, but can induce meaning, e.g. <code>/s/</code> for plural or <code>/…™/</code> for adjective</li>
<li>A nice list of examples can be found <a href="https://englishphonetics.net/english-phonetics-academy/the-44-sounds-of-english-based-on-the-IPA.html">here</a></li>
</ul>
<p>Important for:</p>
<ul>
<li>Speech recognition</li>
<li>Speech-to-text</li>
<li>Text-to-speech</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Examples</p>
<p>Consonant phonemes:</p>
<ul>
<li><code>/b/</code> as in "bat" ü¶á</li>
<li><code>/d í/</code> as in "giraffe" ü¶í</li>
</ul>
<p>Vowel phonemes:</p>
<ul>
<li><code>/iÀê/</code> as in "bee" üêù</li>
<li><code>/√¶/</code> as in "cat" üêà</li>
</ul>
</div>
<h3 id="morphemes-and-lexemes">Morphemes and Lexemes<a class="headerlink" href="#morphemes-and-lexemes" title="Permanent link">&para;</a></h3>
<p>The layer of <strong>words</strong> consists of morphemes and lexemes.</p>
<p>Morphemes:</p>
<ul>
<li>Smallest unit of language that has a <strong>meaning</strong></li>
<li>Formed by a <strong>combination of phonemes</strong></li>
<li>All prefixes or suffixes are morphemes, e.g. <code>multi</code> as in <code>multimedia</code></li>
<li>When breaking down words into their morphemes, variations may occur</li>
</ul>
<p>Lexemes:</p>
<ul>
<li>Consists of one or more morphemes</li>
<li>Multiple words can go back to the same lexeme</li>
<li>Not synonymous with the term "word", rather comparable to an <strong>entry in a dictionary</strong> or an encyclopedia</li>
<li>Different verb forms go back to the same lexeme</li>
</ul>
<p>Important for:</p>
<ul>
<li>Tokenization</li>
<li>Stemming</li>
<li><abbr title="part of speech">POS</abbr>-tagging</li>
<li>Word embeddings</li>
</ul>
<!-- TODO EXAM -->
<div class="admonition example">
<p class="admonition-title">Examples</p>
<p>Breaking down a word into its morphemes:</p>
<ul>
<li>no variation: <span class="arithmatex">\(unbreakable\)</span> üëâ <span class="arithmatex">\(un + break + able\)</span></li>
<li>with variation: <span class="arithmatex">\(unreliability\)</span> üëâ <span class="arithmatex">\(un + rely + able + ity\)</span></li>
</ul>
<p>Rooting back words on its lexemes:</p>
<ul>
<li><span class="arithmatex">\(\{jump, jumps, jumping, ...\}\)</span> üëâ <span class="arithmatex">\(jump\)</span></li>
<li><span class="arithmatex">\(\{buy, bought, buying, ...\}\)</span> üëâ <span class="arithmatex">\(buy\)</span></li>
</ul>
<p>Differentiation of words, lexemes, and morphemes:</p>
<ul>
<li>word <span class="arithmatex">\(football\)</span> (noun) üëâ lexeme: <span class="arithmatex">\(football\)</span> üëâ morphemes: <span class="arithmatex">\(foot + ball\)</span></li>
<li>word <span class="arithmatex">\(cats\)</span> (noun) üëâ lexeme: <span class="arithmatex">\(cat\)</span> üëâ morphemes: <span class="arithmatex">\(cat + s\)</span></li>
<li>word <span class="arithmatex">\(tumbling\)</span> (verb) üëâ lexeme: <span class="arithmatex">\(tumble\)</span> üëâ morphemes: <span class="arithmatex">\(tumble + ing\)</span></li>
<li>word <span class="arithmatex">\(happening\)</span> (verb) üëâ lexeme: <span class="arithmatex">\(happen\)</span> üëâ morphemes: <span class="arithmatex">\(happen + ing\)</span></li>
</ul>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>A <strong>lexeme</strong> is <strong>not synonymous to a word</strong>, but can be thought of as an <strong>abstract word</strong>: if we use lexemes, they become words</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>There is some linguistic <a href="http://www.lilec.it/mmm/wp/wp-content/uploads/2012/09/195-208-Nemo-MMM4.pdf">debate</a> on morphemes and lexemes, but we leave that to linguistics experts. For the scope of this course, the differentiation as given above is sufficient.</p>
</div>
<h3 id="syntax">Syntax<a class="headerlink" href="#syntax" title="Permanent link">&para;</a></h3>
<ul>
<li>Layer of <strong>phrases and sentences</strong></li>
<li>Set of rules to construct grammatically correct sentences out of words</li>
<li>The syntactic structure can be described in many different ways, e.g. grammar</li>
<li>In <abbr title="Natural Language Processing">NLP</abbr>, it is common to describe the anatomy of a sentence using <abbr title="part of speech">POS</abbr> tags</li>
</ul>
<p>The following snippet shows <abbr title="part of speech">POS</abbr>-tagging in Python using the NLTK library and the <a href="https://github.com/slavpetrov/universal-pos-tags">universal tagset</a>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk</span><span class="w"> </span><span class="kn">import</span> <span class="n">pos_tag</span><span class="p">,</span> <span class="n">word_tokenize</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pos_tag</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="s2">&quot;The girl plays tennis.&quot;</span><span class="p">),</span> <span class="n">tagset</span><span class="o">=</span><span class="s2">&quot;universal&quot;</span><span class="p">)</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="p">[</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>    <span class="p">(</span><span class="s1">&#39;The&#39;</span><span class="p">,</span> <span class="s1">&#39;DET&#39;</span><span class="p">),</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>    <span class="p">(</span><span class="s1">&#39;girl&#39;</span><span class="p">,</span> <span class="s1">&#39;NOUN&#39;</span><span class="p">),</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="p">(</span><span class="s1">&#39;plays&#39;</span><span class="p">,</span> <span class="s1">&#39;VERB&#39;</span><span class="p">),</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    <span class="p">(</span><span class="s1">&#39;tennis&#39;</span><span class="p">,</span> <span class="s1">&#39;NOUN&#39;</span><span class="p">),</span>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>    <span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="p">]</span>
</code></pre></div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Consider the following sentence:</p>
<blockquote>
<p><em>"The girl plays tennis."</em></p>
</blockquote>
<p>Grammatical analysis üëâ <em>The girl (subject) plays (verb) tennis (object).</em></p>
<p><abbr title="part of speech">POS</abbr>-tagging using the universal tagset: üëâ <em>The (DET) girl (NOUN) plays (VERB) tennis (NOUN) .(.)</em></p>
</div>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>Imagine you need to analyze a set of tweets and the sentence above changes to:</p>
<blockquote>
<p><em>"The girl üëß plays tennis üéæ."</em></p>
</blockquote>
<p>Given the code above, how would you expect the <abbr title="part of speech">POS</abbr>-tagger to handle emojis?</p>
<p>Find some <a href="https://aclanthology.org/2021.acl-long.110v1.pdf">further information here</a>.</p>
<details class="info">
<summary>Answer</summary>
<p>It would depend on the use case, there are situations where the emoji is a crucial part of the sentence, to indicate emotions (e.g. social media posts).
If it is just about the conveyed information, it is probably OK to remove them during pre-processing.</p>
</details>
</div>
<h3 id="context">Context<a class="headerlink" href="#context" title="Permanent link">&para;</a></h3>
<ul>
<li>Layer of <strong>meaning</strong></li>
<li>Describes how the various parts of language come together and <strong>convey a particular meaning</strong></li>
<li>Includes <strong>world knowledge</strong> and <strong>common sense</strong></li>
<li>Depending on the context, a word or sentence may <strong>change its meaning</strong>, as in the case of ambiguity</li>
<li>Consists of semantics and pragmatics (external context)</li>
<li><strong>Semantics</strong> refers to the direct meaning of words or sentences, without external context</li>
<li><strong>Pragmatics</strong> add world knowledge and enables us to infer implied meaning</li>
</ul>
<p>Important for:</p>
<ul>
<li>Text summarization</li>
<li>Conversational agents</li>
<li>Sentiment analysis</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Consider the following sentence:</p>
<blockquote>
<p>I'm so hungry, I could eat a horse!</p>
</blockquote>
<p><strong>Semantics</strong> would assume that this person wants to eat a horse. üêé</p>
<p><strong>Pragmatics</strong> applies <strong>world knowledge</strong> and infers that this person is very hungry. üç¥</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Being a linguistic expert is not necessary to master <abbr title="Natural Language Processing">NLP</abbr>, but by understanding the basic building blocks of language, we can use the right <abbr title="Natural Language Processing">NLP</abbr> tools in real-world projects.</p>
</div>
<h2 id="challenges-in-nlp">Challenges in <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#challenges-in-nlp" title="Permanent link">&para;</a></h2>
<!-- TODO EXAM -->

<h3 id="ambiguity">Ambiguity<a class="headerlink" href="#ambiguity" title="Permanent link">&para;</a></h3>
<ul>
<li>Occurs when a word, phrase, or sentence has <strong>more than one plausible interpretation</strong></li>
<li>The intended meaning often depends on the <strong>context or world knowledge</strong></li>
<li>Related to <strong>vagueness and uncertainty</strong></li>
<li>Most <strong>languages</strong> are <strong>inherently ambiguous</strong></li>
<li>Humans use it sometimes <strong>on purpose</strong></li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Consider the following sentence:</p>
<blockquote>
<p>The boy ate the cookies on the couch üç™üõã</p>
</blockquote>
<ol>
<li>The boy ate the cookies that were lying on around on the couch</li>
<li>The boy was sitting on the couch while eating cookies</li>
</ol>
</div>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>Which <em>language</em> is supposed to be the least ambiguous of all languages?</p>
<details class="info">
<summary>Answer</summary>
<p>The language of mathematics is unambiguous by design. A mathematical term is means the same everywhere.</p>
<p>Also programming languages are designed to be unambiguous and deterministic.</p>
</details>
</div>
<h3 id="world-knowledge">World Knowledge<a class="headerlink" href="#world-knowledge" title="Permanent link">&para;</a></h3>
<ul>
<li>Set of all facts that most humans, or a targeted group of humans, are aware of</li>
<li>Generally assumed that these facts are known, hence not explicitly mentioned</li>
<li>Can change over time, e.g. <a href="https://en.wikipedia.org/wiki/Heliocentrism">heliocentric model</a></li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Consider the following 2 sentences:</p>
<blockquote>
<ol>
<li>Man bit dog üë®üê∂</li>
<li>Dog bit man üê∂üë®</li>
</ol>
</blockquote>
<p>As humans, we know that only the second sentence is plausible since we assume that dogs are known to bite humans.
Whereas for a machine, if not further specified, both sentences are equally plausible.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>A nice collection of examples of how ambiguity and world knowledge play together are <a href="https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html">Winograd schemas</a>.</p>
<p>Here is an example:</p>
<blockquote>
<p>The city councilmen refused the demonstrators a permit because they [feared/advocated] violence.</p>
</blockquote>
<ol>
<li>If the word is <em>feared</em>, then <em>they</em> presumably refers to the city council.</li>
<li>If it is <em>advocated</em>, then <em>they</em> presumably refers to the demonstrators.</li>
</ol>
<p>Examples like this one are easily disambiguated by the human reader (sometimes we don't even notice that there is ambiguity), mostly because of world knowledge, but they pose challenges to most <abbr title="Natural Language Processing">NLP</abbr> techniques.</p>
<p>The official collection of 150 Winograd schemas can be found <a href="https://cs.nyu.edu/~davise/papers/WinogradSchemas/WSCollection.html">here</a>.</p>
<p>In 2016, there was a <a href="http://commonsensereasoning.org/winograd.html">challenge</a> announced, where the highest score achieved was 58%.</p>
<p>Nowadays, <abbr title="Natural Language Processing">NLP</abbr> systems achieve more than <a href="https://arxiv.org/pdf/2201.02387.pdf">90% accuracy</a>.
A review of approaches as of April 2020 can be found <a href="https://arxiv.org/pdf/2004.13831.pdf">here</a>.</p>
</div>
<h3 id="creativity">Creativity<a class="headerlink" href="#creativity" title="Permanent link">&para;</a></h3>
<ul>
<li>Language not only consists of rules, there are also a lot of creative aspects to it</li>
<li>Language contains a lot of variety, e.g. styles, genres, dialects, aesthetics</li>
<li>There is not "one correct way"</li>
<li>Understanding creativity is a hard difficult problem, not just in <abbr title="Natural Language Processing">NLP</abbr>, but in AI in general (and probably also a philosophical problem)</li>
</ul>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Writing beautiful novels probably requires a high degree of world knowledge and creativity:</p>
<blockquote>
<p><em>He stepped down, trying not to look long at her, as if she were the sun, yet he saw her, like the sun, even without looking.</em></p>
</blockquote>
<p>Leo Tolstoy, Anna Karenina</p>
</div>
<h3 id="diversity">Diversity<a class="headerlink" href="#diversity" title="Permanent link">&para;</a></h3>
<ul>
<li>Many times, no direct mapping between the vocabularies of any two languages</li>
<li>Makes adapting <abbr title="Natural Language Processing">NLP</abbr> solutions to other languages very hard</li>
<li>Build a language-agnostic system, or build separate solutions for each language</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>The German word <a href="https://en.wikipedia.org/wiki/Heimat"><em>Heimat</em></a> has no exact English equivalent.</p>
</div>
<!--
TODO: Anybody who used NLP solutions in another language than english probably has experienced lower performance.
-->

<h2 id="nlp-in-the-era-of-artificial-intelligence"><abbr title="Natural Language Processing">NLP</abbr> in the era of Artificial Intelligence<a class="headerlink" href="#nlp-in-the-era-of-artificial-intelligence" title="Permanent link">&para;</a></h2>
<p>In this section, we will look at <abbr title="Natural Language Processing">NLP</abbr> and how it is related to articial intelligence (AI).</p>
<p>In general, <abbr title="Natural Language Processing">NLP</abbr> aims to give <strong>computers</strong> the ability to <strong>understand text and spoken words</strong> in much the same way human beings can.</p>
<p>It combines computational linguistics with programming, statistics, machine learning, and deep learning.
The field has greatly benefit from recent advancements in ML and DL and is one of the fast-growing research domains in AI.</p>
<p>However, in its simplest forms, <abbr title="Natural Language Processing">NLP</abbr> is <strong>not necessarily based on AI</strong>, and we can also solve some of the simpler tasks with rule-based apporaches.</p>
<p><img alt="Venn Diagram depicting the relation between AI, ML, DL, and NLP" src="../../img/ai-ml-dl-nlp.drawio.svg" title="Relation between AI, ML, DL, and NLP" /></p>
<div class="admonition quote">
<p class="admonition-title">Artificial Intelligence (AI), Oxford English Dictionary</p>
<p>The theory and development of computer systems able to perform tasks normally requiring human intelligence.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>A good read on how AI, ML, and DL are related is <a href="https://www.ibm.com/topics/artificial-intelligence">this article</a> by IBM. <a href="https://www.ibm.com/topics/natural-language-processing">This article</a> gives more details about the role of <abbr title="Natural Language Processing">NLP</abbr> in that context.</p>
</div>
<h3 id="rule-based-nlp">Rule-based <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#rule-based-nlp" title="Permanent link">&para;</a></h3>
<ul>
<li>Defining <strong>rules</strong> for the task to be solved</li>
<li>Utilize lexical resources</li>
<li>Requires developers to have a certain degree of <strong>domain expertise</strong></li>
</ul>
<div class="admonition info">
<p class="admonition-title">Regular expressions (regex)</p>
<p>A very common rule-based tool for text analysis are <strong>regular expressions</strong>, where we define search patterns to find substrings in a text.
Regexes operate deterministically, i.e. it is either a match or not.
<a href="https://docs.python.org/3/library/re.html">Here</a> is a guide using regular expressions with Python, which will be useful throughout the course (as well as your entire journey as a Python developer).</p>
</div>
<div class="admonition example">
<p class="admonition-title">WordNet</p>
<p><a href="https://wordnet.princeton.edu/">WordNet</a> is a database of words and their semantic relationship:</p>
<ul>
<li><strong>Synonyms</strong>: <code>car</code> and <code>automobile</code> üöó (interchangeable)</li>
<li><strong>Hyponyms</strong>: both <code>baseball</code> ‚öæ and <code>tennis</code> üéæ are both <code>sports</code> (aka "super-subordinate" relation)</li>
<li><strong>Meronyms</strong>: <code>arm</code> üí™ and <code>foot</code> ü¶∂ are <code>body</code> parts (aka "part-whole" relation)</li>
</ul>
</div>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>What <abbr title="Natural Language Processing">NLP</abbr> tasks do you think could be solved using rule-based approaches? What are the advantages and limitations of such approaches?</p>
<details class="info">
<summary>Answer</summary>
<p>Examples would be sentiment analysis based on word count, or a regex to map tracking numbers to shipping companies.</p>
<ul>
<li>advantages: light-weight, quick &amp; easy compared to DL models, are deterministic</li>
<li>limitations: hard to solve more complex <abbr title="Natural Language Processing">NLP</abbr> tasks</li>
</ul>
<p>We can use rule based approaches to bridge gaps between <abbr title="Natural Language Processing">NLP</abbr> systems, e.g. eliminate mistakes made by AI with rule-based approaches</p>
</details>
</div>
<h3 id="machine-learning-for-nlp">Machine Learning for <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#machine-learning-for-nlp" title="Permanent link">&para;</a></h3>
<ul>
<li>Branch of AI</li>
<li>Algorithms that can learn to perform tasks based on a large number of <strong>examples</strong></li>
<li>No explicit instructions required, algorithm learns <strong>patterns</strong></li>
<li>Requires <strong>numeric representation</strong> (aka "features") of the training data</li>
<li>ML can be applied to textual data similar to other forms of data</li>
<li>A special focus needs to be put on <strong>pre-processing</strong> and <strong>feature extraction</strong></li>
<li>training a model is then "business as usual"</li>
</ul>
<h4 id="supervised-learning">Supervised learning<a class="headerlink" href="#supervised-learning" title="Permanent link">&para;</a></h4>
<ul>
<li>learn <strong>mapping function</strong> from input to output</li>
<li>requires a large number of <strong>labeled training data</strong>, i.e. known input-output pairs</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>An <strong>email spam filter</strong> is a common example where supervised learning is used in <abbr title="Natural Language Processing">NLP</abbr>.</p>
</div>
<h4 id="unsupervised-learning">Unsupervised learning<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h4>
<ul>
<li>Aims to find hidden patterns in given input data</li>
<li>Output is unknown, i.e. works with <strong>unlabeled data</strong></li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>An example where unsupervised learning is used in <abbr title="Natural Language Processing">NLP</abbr> is <strong>topic modeling</strong>, where we try to identify topics in a large collection of text data, e.g. news articles, without prior knowledge of these topics.
A simple approach to topic modeling is a <a href="https://en.wikipedia.org/wiki/Tag_cloud">tag cloud</a>.</p>
</div>
<h3 id="deep-learning-for-nlp">Deep Learning for <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#deep-learning-for-nlp" title="Permanent link">&para;</a></h3>
<p>When we speak of using deep learning for <abbr title="Natural Language Processing">NLP</abbr>, this encompasses all algorithms based on <strong>artifical neural networks</strong>.
Deep learing approaches in <abbr title="Natural Language Processing">NLP</abbr> led to <strong>significant advances</strong> in the recent year in the field.</p>
<p>This section gives a brief overview of the terms that are used in this context.</p>
<h4 id="language-models">Language Models<a class="headerlink" href="#language-models" title="Permanent link">&para;</a></h4>
<ul>
<li>System that is trained to <strong>understand and generate</strong> human-like text</li>
<li>Designed to <strong>predict</strong> and generate sequences of words or characters based on the input it receives</li>
<li>Learns <strong>patterns, structures, and relationships</strong> within a given language by being exposed to <strong>large amounts of text data</strong></li>
<li>They can be based on <strong>various architectures</strong>, including RNNs, LSTMs, CNNs, and more recently, transformers</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>GPT-3, based on the transformer architecture, is an example of a powerful language model.</p>
</div>
<h4 id="convolutional-neural-networks-cnns">Convolutional Neural Networks (CNNs)<a class="headerlink" href="#convolutional-neural-networks-cnns" title="Permanent link">&para;</a></h4>
<ul>
<li>Adapted from computer vision tasks</li>
<li>Require <strong>word embeddings</strong> to build sentences matrices, which can be treated analogously to images</li>
</ul>
<h4 id="recurrent-neural-networks-rnns">Recurrent Neural Networks (RNNs)<a class="headerlink" href="#recurrent-neural-networks-rnns" title="Permanent link">&para;</a></h4>
<ul>
<li>language is sequential by nature, e.g. text flows from one direction to another</li>
<li>RNNs are a type of neural network designed for <strong>sequential data</strong>, making them suitable for tasks where the order of the input matters</li>
<li>Can remember what they have processed so far, but cannot remember long contexts</li>
</ul>
<h4 id="long-short-term-memory-lstm">Long Short-Term Memory (LSTM)<a class="headerlink" href="#long-short-term-memory-lstm" title="Permanent link">&para;</a></h4>
<ul>
<li>LSTMs are a specific type of RNN designed to address the vanishing gradient problem, enabling better learning of long-range dependencies in sequential data.</li>
<li>Let go of <strong>irrelevant context</strong>, and only remember the context that is required to solve the task at hand</li>
</ul>
<h4 id="transformers">Transformers<a class="headerlink" href="#transformers" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Type of architecture</strong> that has gained prominence in <abbr title="Natural Language Processing">NLP</abbr></li>
<li>Use <strong>attention mechanisms</strong> to capture relationships between different parts of a sequence simultaneously, making them effective for processing sequential data, including language</li>
<li>Look at surrounding words to derive context (e.g. bank as a river bank or financial institution)</li>
</ul>
<h4 id="transfer-learning">Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permanent link">&para;</a></h4>
<ul>
<li>Transfer learning is a machine learning <strong>paradigm</strong> where a model trained on one task is <strong>adapted or fine-tuned</strong> for a different but related task</li>
<li>Often used to leverage <strong>pre-trained models</strong> for specific applications</li>
<li>The model is able to <strong>transfer</strong> the pre-trained knowledge for downstream tasks</li>
</ul>
<h4 id="foundation-models">Foundation Models<a class="headerlink" href="#foundation-models" title="Permanent link">&para;</a></h4>
<ul>
<li>The term <strong>foundation model</strong> refers to <strong>large-scale</strong> language models <strong>based on the transformer</strong> architecture</li>
<li>They serve as a <strong>starting point</strong> for various <abbr title="Natural Language Processing">NLP</abbr> tasks</li>
<li>It emphasizes the idea that a <strong>pre-trained model</strong> forms the <strong>foundation</strong> and can be adapted for various tasks</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>GPT-3 is known to be trained on 45 TB of text data and the model has about 175 billion parameters.</p>
</div>
<h4 id="attention">Attention<a class="headerlink" href="#attention" title="Permanent link">&para;</a></h4>
<ul>
<li>The attention mechanism is a key component of the transformer model architecture and plays a crucial role in capturing <strong>contextual information across sequences</strong>.</li>
<li>Attention mechanisms, particularly <strong>self-attention</strong> in the context of transformers, allow models to <strong>focus on different parts of the input sequence</strong> when making predictions.</li>
<li>Especially beneficial for capturing long-range dependencies.</li>
<li>In general, attention is the ability to <strong>focus on important things and ignore irrelevant things</strong>, as certain parts of a sentence are more important than others</li>
</ul>
<h3 id="limitations-of-ai-in-nlp">Limitations of AI in <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#limitations-of-ai-in-nlp" title="Permanent link">&para;</a></h3>
<p>DL has brought <abbr title="Natural Language Processing">NLP</abbr> to the next level, and powerful transformer models have become SOTA in most <abbr title="Natural Language Processing">NLP</abbr> tasks.
However, DL is not the silver bullet for all <abbr title="Natural Language Processing">NLP</abbr> tasks, especially when it comes to industrial applications<sup id="fnref2:2"><a class="footnote-ref" href="#fn:2">2</a></sup>:</p>
<ul>
<li>
<p><strong>Overfitting on small datasets</strong>:
  DL models need more training data to fit all their parameters, but many times, sufficient training data is not available.
  Hence, they overfit on small datasets and have poor generalization capabilities.
  Also, consider Occam's razor: given that all other conditions are equal, the simpler solution should be preferred.</p>
</li>
<li>
<p><strong>Domain adaption</strong>:
  Most DL models are trained on common domains (e.g. news articles).
  If we try to use them for a different domain (e.g. social media), we may observe poor performance.
  This is because language is domain-specific (think of all the emojis and all the slang words in social media posts).
  Therefore, a well-designed rule-based domain-specific that encodes all required knowledge may outperform a complex DL model.</p>
</li>
<li>
<p><strong>Explainable models</strong>:
  Most of the time, DL models work like a black box, but in many use cases, industries demand interpretable results that can be explained to end users.
  In such cases, traditional approaches might be more useful.
  For example, with Naive Bayes for sentiment analysis, the effect of positive vs. negative words can be easily explained.
  While for computer vision, many techniques exist to explain model predictions, this is not as common in <abbr title="Natural Language Processing">NLP</abbr>.</p>
</li>
<li>
<p><strong>Common sense and world knowledge</strong>
  As mentioned earlier, teaching <abbr title="Natural Language Processing">NLP</abbr> models common sense, and world knowledge remains a challenge.
  Also, logical reasoning falls into this category, and understanding events and understand their consequences are complex tasks for machines.</p>
</li>
<li>
<p><strong>Cost</strong>
  Many cost factors apply to complex <abbr title="Natural Language Processing">NLP</abbr> models, especially when DL-based.
  They require a lot of (labeled) data, and training not only takes a lot of time but also consumes a lot of hardware resources.
  In addition, such large models may have latency issues.</p>
</li>
<li>
<p><strong>Deployment</strong>
  In some use cases, some deployment constraints apply.
  For example, the <abbr title="Natural Language Processing">NLP</abbr> system needs to run on an embedded device with limited resources, or even offline, rather than in the cloud.</p>
</li>
</ul>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>Consider the following sentence:</p>
<blockquote>
<p>John walks out of the house into his garden.</p>
</blockquote>
<p>As humans, we immediately reason that John's current location is the garden, and his previous location was inside his house, but this kind of reasoning is hard to incorporate into machines.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Is AI dumber than a cat?</p>
<p>Read in <a href="https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5">this</a> Wall Street Journal article why <a href="https://www.linkedin.com/in/yann-lecun/">Yann LeCun</a>, Meta's Chief AI Scientist, thinks that AI is dumber than a cat. üê±</p>
</div>
<div class="admonition note">
<p class="admonition-title">Resource consumption of ChatGPT</p>
<p>An interesting <a href="https://twitter.com/tomgoldsteincs/status/1600196981955100694">Twitter thread</a> from Professor Tom Goldstein gives some easily digestible figures about the resources consumed by ChatGPT.
This is not what you can invest in your everyday <abbr title="Natural Language Processing">NLP</abbr> system!</p>
</div>
<div class="admonition warning">
<p class="admonition-title">AI is not always the best answer</p>
<p>DL has led to significant advances in <abbr title="Natural Language Processing">NLP</abbr>, but be aware that DL is not always the go-to solution for <abbr title="Natural Language Processing">NLP</abbr> projects.
Most of the SOTA models are trained on common and very clean datasets, which does not apply to many industry use cases.</p>
<p>Therefore it is even more important to understand the fundamentals of <abbr title="Natural Language Processing">NLP</abbr> and apply the right method for the right use case, as cutting-edge solutions may not always be the best choice.</p>
<p>In many real-world scenarios, the focus is more on the data pipeline side.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>In a hate speech detection project on tweets, a lesson learned was that a simple Naive Bayes prototype performed similarly, if not better, than a fine-tuned BERT model. Why do you think that is?</p>
<details class="info">
<summary>Answer</summary>
<ul>
<li>Tweets are very short snippets of text and contain a lot of slang or informal words, as well as emojis.</li>
<li>Models like BERT are trained on rather "clean" corpora, like news articles.</li>
<li>We can adapt that, but for short text like tweets, BERT probably provides an overhead, and we found that a simple approach tailored to that exact use case leads to similar if not better results, with much less effort.</li>
</ul>
</details>
</div>
<div class="admonition tip">
<p class="admonition-title">Start simple and improve iteratively</p>
<p>In many cases, it makes sense to start with a simple baseline model and adjust and improve model complexity iteratively.</p>
<p>This is useful advice in many areas of software development. üòÉ</p>
<p><img alt="Occam's Razor Comic" src="https://phdcomics.com/comics/archive/phd101209s.gif" title="Occam's Razor Comic" /></p>
</div>
<h2 id="key-takeaways">Key Takeaways<a class="headerlink" href="#key-takeaways" title="Permanent link">&para;</a></h2>
<ul>
<li>Our modern lives are full of <abbr title="Natural Language Processing">NLP</abbr> applications, and we encounter them every day.</li>
<li>When building an <abbr title="Natural Language Processing">NLP</abbr> system or application, we need to <strong>understand the problem</strong> we are trying to solve and the <strong><abbr title="Natural Language Processing">NLP</abbr> tasks</strong> that are required to solve it.</li>
<li>To work on <abbr title="Natural Language Processing">NLP</abbr> problems, we need to have a basic understanding of <strong>how we can approach language programmatically</strong>.</li>
<li>It is also important to understand if we are looking at a problem from a research or engineering <strong>perspective</strong>.</li>
<li>The <strong>basic building blocks of language</strong> are phonemes, morphemes &amp; lexemes, syntax, and context.</li>
<li>Trying to map language to a computer system poses several <strong>challenges</strong>, as language is inherently ambiguous, requires world knowledge, and involves creativity and diversity.</li>
<li>It is very common to make use of <strong>AI to solve <abbr title="Natural Language Processing">NLP</abbr> problems</strong>, but not every <abbr title="Natural Language Processing">NLP</abbr> problem requires AI. Depending on the use case, <strong>rule-based approaches</strong> may be sufficient.</li>
<li>Recent advancement in <abbr title="Natural Language Processing">NLP</abbr> is mainly driven by <strong>deep learning</strong> and <strong>transformer models</strong> and their ability to learn from large amounts of data. This is the beginning of a new era in <abbr title="Natural Language Processing">NLP</abbr>.</li>
</ul>
<!-- footnotes -->
<!-- markdownlint-disable MD053 -->
<!-- markdownlint-disable MD041 -->
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><a href="https://www.ibm.com/think/topics/natural-language-processing">https://www.ibm.com/think/topics/natural-language-processing</a>&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>Vajjala, Sowmya, S.V. Bharathi, Bodhisattwa Majumder, Anuj Gupta, and Harshit Surana. <em>Practical Natural Language Processing: A Comprehensive Guide to Building Real-world <abbr title="Natural Language Processing">NLP</abbr> Systems</em>. Sebastopol, CA: O'Reilly Media, 2020. <a href="https://www.practicalnlp.ai/">https://www.practicalnlp.ai/</a>.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p><a href="https://www.databricks.com/sites/default/files/2023-06/compact-guide-to-large-language-models.pdf">https://www.databricks.com/sites/default/files/2023-06/compact-guide-to-large-language-models.pdf</a>&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:4">
<p><a href="https://www.deeplearning.ai/resources/natural-language-processing/">https://www.deeplearning.ai/resources/natural-language-processing/</a>&#160;<a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
</ol>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:pascal.keilbach@htwg-konstanz.de" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/pkeilbach/htwg-practical-nlp" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.tooltips", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>