
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A practical course on natural language processing @ HTWG Konstanz.">
      
      
      
      
        <link rel="prev" href="../introduction/">
      
      
        <link rel="next" href="../feature_extraction/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Preprocessing - Practical NLP</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#preprocessing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Practical NLP" class="md-header__button md-logo" aria-label="Practical NLP" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Practical NLP
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Preprocessing
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/pkeilbach/htwg-practical-nlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    pkeilbach/htwg-practical-nlp
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Welcome

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../course_profile/" class="md-tabs__link">
        
  
  
    
  
  About

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../getting_started/" class="md-tabs__link">
        
  
  
    
  
  Getting Started

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../preface/" class="md-tabs__link">
          
  
  
    
  
  Lectures

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../assignments/" class="md-tabs__link">
        
  
  
    
  
  Assignments

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../presentations/" class="md-tabs__link">
        
  
  
    
  
  Presentations

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../faq/" class="md-tabs__link">
        
  
  
    
  
  FAQ

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../exam/" class="md-tabs__link">
        
  
  
    
  
  Exam

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Practical NLP" class="md-nav__button md-logo" aria-label="Practical NLP" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Practical NLP
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/pkeilbach/htwg-practical-nlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    pkeilbach/htwg-practical-nlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Welcome
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../course_profile/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Lectures
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Lectures
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../preface/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Preface
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Preprocessing
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Preprocessing
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-pipeline-concept-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      The pipeline concept in NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acquiring-data-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Acquiring data for NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#working-with-text-data" class="md-nav__link">
    <span class="md-ellipsis">
      Working with text data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Working with text data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lowercasing" class="md-nav__link">
    <span class="md-ellipsis">
      Lowercasing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remove-punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      Remove punctuation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remove-html-tags-and-urls" class="md-nav__link">
    <span class="md-ellipsis">
      Remove HTML tags and URLs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-common-text-processing-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Other common text processing steps
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokenization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stopword-removal" class="md-nav__link">
    <span class="md-ellipsis">
      Stopword removal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stemming" class="md-nav__link">
    <span class="md-ellipsis">
      Stemming
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lemmatization" class="md-nav__link">
    <span class="md-ellipsis">
      Lemmatization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#converting-tokens-into-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Converting tokens into embeddings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-special-context-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      Adding special context tokens
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../feature_extraction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Feature Extraction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../logistic_regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logistic Regression
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../naive_bayes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Naive Bayes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vector_space_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vector Space Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minimum_edit_distance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Minimum Edit Distance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../language_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Language Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../word_embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Word Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sequence_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sequence Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../attention_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../further_reading/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Where to go from here?
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../assignments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignments
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../presentations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Presentations
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAQ
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../exam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Exam
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-pipeline-concept-in-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      The pipeline concept in NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acquiring-data-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Acquiring data for NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#working-with-text-data" class="md-nav__link">
    <span class="md-ellipsis">
      Working with text data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Working with text data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lowercasing" class="md-nav__link">
    <span class="md-ellipsis">
      Lowercasing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remove-punctuation" class="md-nav__link">
    <span class="md-ellipsis">
      Remove punctuation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#remove-html-tags-and-urls" class="md-nav__link">
    <span class="md-ellipsis">
      Remove HTML tags and URLs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-common-text-processing-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Other common text processing steps
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokenization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#stopword-removal" class="md-nav__link">
    <span class="md-ellipsis">
      Stopword removal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stemming" class="md-nav__link">
    <span class="md-ellipsis">
      Stemming
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lemmatization" class="md-nav__link">
    <span class="md-ellipsis">
      Lemmatization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#converting-tokens-into-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Converting tokens into embeddings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-special-context-tokens" class="md-nav__link">
    <span class="md-ellipsis">
      Adding special context tokens
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      Key takeaways
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="preprocessing">Preprocessing<a class="headerlink" href="#preprocessing" title="Permanent link">&para;</a></h1>
<p>Natural language data is inherently <strong>unstructured</strong> and often contains noise, irregularities, and inconsistencies.</p>
<p>Machine learning models <strong>cannot process raw text directly</strong>.
Since text is categorical, it isnâ€™t compatible with the mathematical operations used to implement and train neural networks. Therefore, we need a way to represent words as continuous-valued vectors (aka <a href="https://pkeilbach.github.io/htwg-practical-nlp/lectures/word_embeddings/">embeddings</a>).<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<div class="admonition info">
<p class="admonition-title">Embeddings</p>
<p>As we will learn <a href="https://pkeilbach.github.io/htwg-practical-nlp/lectures/word_embeddings/">later</a>, embeddings are a numerical representation of a token.
In the beginning, we initialize them <strong>randomly</strong>.
Later, during training, they are optimized to represent the token in a way that is useful for the task at hand.</p>
</div>
<p>The <strong>goal</strong> of preprocessing is to transform raw text data into such embeddings so that we can use them for training machine learning models.</p>
<p>In this lecture, we will look at some <strong>common preprocessing</strong> steps that are essential for preparing text data for <abbr title="Natural Language Processing">NLP</abbr> tasks.</p>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>The image shows the typical preprocessing steps of text data:<sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<p><img alt="From input text to embeddings" src="../../img/preprocessing.drawio.svg" title="From input text to embeddings" /></p>
<ul>
<li>When we have the raw input text available, we need to <a href="#tokenization"><strong>tokenize</strong></a> it.</li>
<li>Afterwards, the each individual token is <strong>mapped to an ID</strong>.</li>
<li>Then, we convert the token IDs into <strong>embedding vectors</strong>.</li>
</ul>
<!-- TODO EXAM -->
<h2 id="the-pipeline-concept-in-nlp">The pipeline concept in <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#the-pipeline-concept-in-nlp" title="Permanent link">&para;</a></h2>
<p>Like with many other complex problems, in <abbr title="Natural Language Processing">NLP</abbr>, it makes sense to break the problem that needs to be solved down into several sub-problems.
This step-by-step processing is also referred to as a <em>pipeline</em>.
Using a pipeline and breaking down an <abbr title="Natural Language Processing">NLP</abbr> problem into different steps offers several advantages that contribute to the overall efficiency and effectiveness of the <abbr title="Natural Language Processing">NLP</abbr> process:</p>
<ol>
<li>
<p><strong>Modularization and Reusability:</strong>
    Breaking down the <abbr title="Natural Language Processing">NLP</abbr> process into distinct steps allows for modularization.
    Each step can be designed as a separate module with well-defined inputs and outputs.
    This modularity promotes code reusability and makes swapping out or updating individual components easier without affecting the entire system.</p>
</li>
<li>
<p><strong>Complexity Management:</strong>
    <abbr title="Natural Language Processing">NLP</abbr> tasks can be intricate, involving numerous subtasks and techniques.
    By dividing the problem into manageable steps, it becomes easier to focus on each aspect separately.
    This simplifies the development, debugging, and maintenance of the <abbr title="Natural Language Processing">NLP</abbr> solution.</p>
</li>
<li>
<p><strong>Parallelization and Efficiency:</strong>
    Different steps of the pipeline can often be executed in parallel, speeding up the overall process.
    For instance, while one part of the pipeline preprocesses data, another can perform feature engineering, enhancing computational efficiency.</p>
</li>
<li>
<p><strong>Experimentation and Iteration:</strong>
    A structured pipeline allows researchers and practitioners to experiment with various techniques and algorithms at different stages.
    This iterative approach facilitates the testing of different configurations and helps identify the best-performing components for each step.</p>
</li>
<li>
<p><strong>Collaboration:</strong>
    When working in teams, a well-defined pipeline allows team members to focus on specific stages of the <abbr title="Natural Language Processing">NLP</abbr> process, enhancing collaboration and specialization.
    Team members can work on their respective areas of expertise while contributing to the overall project.</p>
</li>
<li>
<p><strong>Debugging and Troubleshooting:</strong>
    If a problem arises in a specific stage of the pipeline, it's easier to identify the source and address the issue when the process is divided into distinct steps.
    This targeted approach simplifies debugging and reduces the scope of potential errors.</p>
</li>
<li>
<p><strong>Scalability:</strong>
    As <abbr title="Natural Language Processing">NLP</abbr> projects grow in complexity, a modular pipeline can accommodate the addition of new components or steps as needed.
    This scalability is especially important when dealing with evolving data sources and changing requirements.</p>
</li>
<li>
<p><strong>Adaptation to Different Tasks:</strong>
    The pipeline structure can be adapted and reused for various <abbr title="Natural Language Processing">NLP</abbr> tasks.
    By modifying or replacing specific steps, the same pipeline can be applied to tasks like sentiment analysis, text summarization, machine translation, and more.</p>
</li>
<li>
<p><strong>Documentation and Transparency:</strong>
    A well-defined pipeline provides a clear outline of the entire <abbr title="Natural Language Processing">NLP</abbr> process.
    This documentation is valuable for sharing insights, collaborating, and ensuring transparency in the development and deployment process.</p>
</li>
</ol>
<p>In essence, the concept of a pipeline in <abbr title="Natural Language Processing">NLP</abbr> enhances organization, flexibility, collaboration, and maintainability throughout the development lifecycle.
It facilitates the transformation of raw text data into valuable insights by systematically addressing the challenges specific to natural language processing tasks.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Pipeline processing can be found in many areas of machine learning and computer science in general, e.g., data engineering or DevOps.
An <abbr title="Natural Language Processing">NLP</abbr> pipeline can be seen as an adapted machine learning pipeline, as many of its steps apply to machine learning in general.</p>
</div>
<p>The following figure shows a generic <abbr title="Natural Language Processing">NLP</abbr> pipeline, followed by a high-level description of each step.
The color indicates whether the pipeline step is relevant for the course.<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup><sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup></p>
<p><img alt="Generic NLP pipeline which indicates the scope for this course" src="../../img/nlp-pipeline.drawio.svg" title="Generic NLP pipeline" /></p>
<ol>
<li>
<p><strong>Business Goal</strong>
    An organization considering ML should have a clear idea of the problem and the business value to be gained by solving that problem.
    You must be able to measure business value against specific business objectives and success criteria.</p>
</li>
<li>
<p><strong>Data Acquisition:</strong>
    In this initial step, you gather the raw text data that you will use for your <abbr title="Natural Language Processing">NLP</abbr> task.
    This could involve scraping websites, accessing databases, or any other method to collect relevant text documents.</p>
</li>
<li>
<p><strong>Pre-Processing:</strong>
    Pre-processing includes a series of tasks like tokenization (breaking text into words or subword units), lowercasing, and stemming/lemmatization (reducing words to their base form).
    This step helps standardize the text and make it ready for further analysis.</p>
</li>
<li>
<p><strong>Feature Engineering:</strong>
    Feature engineering involves transforming the pre-processed text into numerical representations that machine learning models can work with.
    This could include techniques like <abbr title="Term Frequency-Inverse Document Frequency">TF-IDF</abbr> or word embeddings like Word2Vec or GloVe.</p>
</li>
<li>
<p><strong>Modeling:</strong>
    In this step, you select and train a machine learning or deep learning model that suits your <abbr title="Natural Language Processing">NLP</abbr> task, such as text classification, <abbr title="Named Entity Recognition">NER</abbr>, or machine translation.
    The model learns patterns from the numerical representations of the text data.</p>
</li>
<li>
<p><strong>Evaluation:</strong>
    After training your model, you need to assess its performance.
    Evaluation involves using metrics like accuracy, precision, recall, F1-score, or others, depending on the task, to measure how well the model is performing on unseen data.</p>
</li>
<li>
<p><strong>Deployment:</strong>
    Once you're satisfied with your model's performance, you deploy it to a production environment where it can be used to make predictions on new incoming text data.
    This could involve integrating it into a web application, API, or other systems.</p>
</li>
<li>
<p><strong>Monitoring and Model Updating:</strong>
    After deployment, continuously monitoring the model's performance in real-world scenarios is essential.
    Suppose the model's accuracy drops or its predictions become less reliable over time due to changing patterns in the data. In that case, you might need to retrain or update the model to maintain its effectiveness.</p>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on the specific <abbr title="Natural Language Processing">NLP</abbr> task and the complexity of the data, you might need to delve deeper into each step and consider additional techniques or subtasks.</p>
</div>
<h2 id="acquiring-data-for-nlp">Acquiring data for <abbr title="Natural Language Processing">NLP</abbr><a class="headerlink" href="#acquiring-data-for-nlp" title="Permanent link">&para;</a></h2>
<p>Data acquisition techniques in Natural Language Processing (<abbr title="Natural Language Processing">NLP</abbr>) are crucial for obtaining high-quality data to train and evaluate models.
Here's an overview of four common data acquisition techniques:</p>
<ol>
<li>
<p><strong>Web Scraping:</strong>
    This involves extracting data from websites.
    It's widely used for collecting large amounts of text data from various sources, such as news articles, blogs, and social media platforms.
    Libraries like <a href="https://www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a> or <a href="https://scrapy.org/">Scrapy</a> are commonly used for web scraping.</p>
</li>
<li>
<p><strong>Pre-existing Datasets:</strong>
    Many publicly available datasets have been curated for specific <abbr title="Natural Language Processing">NLP</abbr> tasks.
    Examples include the <a href="https://developer.imdb.com/non-commercial-datasets/">IMDb dataset</a> for sentiment analysis, the <a href="https://catalog.ldc.upenn.edu/LDC99T42">Penn Treebank</a> for language modeling, or the <a href="https://www.clips.uantwerpen.be/conll2003/ner/">CoNLL dataset</a> for <abbr title="Named Entity Recognition">NER</abbr>.
    Also, these datasets serve as benchmarks for various <abbr title="Natural Language Processing">NLP</abbr> tasks.</p>
</li>
<li>
<p><strong>Data Augmentation:</strong>
    Data augmentation involves creating new data samples from existing ones by applying various transformations.
    In <abbr title="Natural Language Processing">NLP</abbr>, this can involve techniques like paraphrasing, synonym replacement, and perturbation of sentences.
    Augmentation helps increase the diversity of the training data and can improve model generalization.
    A popular tool (not only) for data augmentation is <a href="https://www.snorkel.org/">snorkel</a>.</p>
</li>
</ol>
<p>In many cases, it's a <strong>combination of these techniques</strong> that makes a well-rounded and robust dataset for training and evaluating <abbr title="Natural Language Processing">NLP</abbr> models.
The choice of technique depends on the specific task, available resources, and ethical considerations.</p>
<p>The following code snippet is an example that shows how to parse a Wikipedia page.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">bs4</span><span class="w"> </span><span class="kn">import</span> <span class="n">BeautifulSoup</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://en.wikipedia.org/wiki/Python_(programming_language)&#39;</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="n">infobox</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;table&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s1">&#39;infobox&#39;</span><span class="p">)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="n">abstract_text</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="k">if</span> <span class="n">infobox</span><span class="p">:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">rows</span> <span class="o">=</span> <span class="n">infobox</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;tr&#39;</span><span class="p">)</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">:</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="n">header</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;th&#39;</span><span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="k">if</span> <span class="n">header</span> <span class="ow">and</span> <span class="s1">&#39;Paradigm&#39;</span> <span class="ow">in</span> <span class="n">header</span><span class="o">.</span><span class="n">text</span><span class="p">:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>            <span class="n">abstract</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find_next</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>            <span class="k">if</span> <span class="n">abstract</span><span class="p">:</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>                <span class="n">abstract_text</span> <span class="o">=</span> <span class="n">abstract</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>                <span class="k">break</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="k">if</span> <span class="n">abstract_text</span><span class="p">:</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">abstract_text</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Abstract not found.&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>As you can see, it already involves quite some custom logic and pitfalls and won't work if Wikipedia makes changes that affect the HTML tree.
Many Websites offer APIs that allow much more straightforward access to their data via HTTP call, e.g., the <a href="https://developer.twitter.com/en/docs/twitter-api">Twitter API</a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While such techniques are valuable, each comes with its own challenges:</p>
<ul>
<li>Web scraping can be legally and ethically complex and often requires a lot of custom logic</li>
<li>Pre-existing datasets might not always align perfectly with your task</li>
<li>Human annotation can be expensive and time-consuming</li>
<li>Data augmentation requires creativity to maintain semantic meaning.</li>
</ul>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>As you may know, <a href="https://www.kaggle.com/">kaggle</a> is an excellent source for browsing public datasets for various use cases.
Also, the <a href="https://www.ldc.upenn.edu/">Linguistic Data Consortium</a> has curated a <a href="https://catalog.ldc.upenn.edu/topten">top ten list</a> of datasets for <abbr title="Natural Language Processing">NLP</abbr> tasks.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>The <a href="https://github.com/pkeilbach/htwg-practical-nlp/blob/main/notebooks/data_acquisition.ipynb"><code>data_acquisition.ipynb</code></a> notebook demonstrates how to acquire data from New York Times articles using the <a href="https://developer.nytimes.com/apis">New York Times API</a>.</p>
</div>
<h2 id="working-with-text-data">Working with text data<a class="headerlink" href="#working-with-text-data" title="Permanent link">&para;</a></h2>
<h3 id="lowercasing">Lowercasing<a class="headerlink" href="#lowercasing" title="Permanent link">&para;</a></h3>
<p>Convert all text to lowercase to ensure consistent handling of words regardless of their case.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;Welcome to the HTWG practical NLP course&quot;</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="s1">&#39;welcome to the htwg practical nlp course&#39;</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Back in the days, having all text lowercase was common practice because it had a positive impact on the performance of machine learning models.</p>
<p>But in the era of large language models (LLMs), lowercasing is not common anymore,
and capitalization helps LLMs distinguish between proper nouns and common nouns, understand sentence structure, and learn to generate text with proper capitalization.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>In some cases, the case of the text may carry valuable information, such as in tasks related to <abbr title="Named Entity Recognition">NER</abbr>, where distinguishing between "US" (the country) and "us" (the pronoun) is essential.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Depending on the use case, you may need to do other string operations.
Python offers a lot of useful <a href="https://docs.python.org/3/library/stdtypes.html#string-methods">string methods</a> to work with text data.</p>
</div>
<h3 id="remove-punctuation">Remove punctuation<a class="headerlink" href="#remove-punctuation" title="Permanent link">&para;</a></h3>
<p>Punctuation marks like commas, periods, and semicolons can add complexity to text, but they might not always contribute essential information. By removing them, the text is simplified, and the complexity of the data is reduced, which can make it easier for certain <abbr title="Natural Language Processing">NLP</abbr> tasks to process and analyze.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">word_tokenize</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;Hey, what are you up to? Let&#39;s have a pizza tonight!&quot;</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalnum</span><span class="p">()]</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="p">[</span><span class="s1">&#39;Hey&#39;</span><span class="p">,</span> <span class="s1">&#39;what&#39;</span><span class="p">,</span> <span class="s1">&#39;are&#39;</span><span class="p">,</span> <span class="s1">&#39;you&#39;</span><span class="p">,</span> <span class="s1">&#39;up&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;Let&#39;</span><span class="p">,</span> <span class="s1">&#39;have&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;pizza&#39;</span><span class="p">,</span> <span class="s1">&#39;tonight&#39;</span><span class="p">]</span>
</code></pre></div>
<h3 id="remove-html-tags-and-urls">Remove HTML tags and URLs<a class="headerlink" href="#remove-html-tags-and-urls" title="Permanent link">&para;</a></h3>
<p>When dealing with text from web pages, HTML tags are often present and need to be removed.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">bs4</span><span class="w"> </span><span class="kn">import</span> <span class="n">BeautifulSoup</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">html</span> <span class="o">=</span> <span class="s2">&quot;&lt;div&gt;&lt;h1&gt;Hello, World!&lt;/h1&gt;&lt;p&gt;This is a &lt;strong&gt;simple&lt;/strong&gt; HTML page.&lt;/p&gt;&lt;/div&gt;&quot;</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="s1">&#39;Hello, World!This is a simple HTML page.&#39;</span>
</code></pre></div>
<p>Usually, it's also a good idea to remove URLs, as they often contain random characters and symbols and, therefore, add noise to the text.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While you could also achieve it with a simple regex <code>re.sub(r'&lt;.*?&gt;', '', html)</code>, it might not cover all edge cases and HTML entities like, e.g., <code>&amp;nsbm</code>.
Therefore, using a well-established library for such tasks is generally a better approach.</p>
</div>
<h3 id="other-common-text-processing-steps">Other common text processing steps<a class="headerlink" href="#other-common-text-processing-steps" title="Permanent link">&para;</a></h3>
<p>Here are some other common text processing steps worth mentioning:</p>
<ol>
<li>
<p><strong>Handling Numbers:</strong>
    Decide whether to keep or remove numbers based on the analysis's goals.
    You might replace numbers with placeholders like <code>NUM</code> or convert them to words.</p>
</li>
<li>
<p><strong>Handling Special Characters</strong>
    Special characters like "+" or emojis often convey a meaning.
    Depending on your application, you can choose to preserve emojis as-is, replace them with their textual descriptions, e.g., "â˜ºï¸" becomes "smiley face", or remove them altogether.
    Not surprisingly, emojis are helpful for sentiment analysis.</p>
</li>
<li>
<p><strong>Removing whitespace:</strong>
    Extra spaces, tabs <code>\t</code>, or line breaks <code>\n</code> should be normalized to a single space to ensure consistent formatting.</p>
</li>
<li>
<p><strong>Spelling Correction:</strong>
    Human-typed data often has spelling errors. Custom solutions are usually not robust enough, but online services like <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/bing-spell-check/quickstarts/python">Bing Spell Check</a> offer REST APIs to tackle the spelling correction problem more sophisticatedly.</p>
</li>
<li>
<p><strong>Contractions expansion:</strong>
    Especially in the English language, expanding contractions like "can't" to "cannot" or "I'm" to "I am." should be resolved to ensure consistent word representations.</p>
</li>
<li>
<p><strong>Handling Abbreviations and Acronyms:</strong>
    Expanding abbreviations and acronyms to their full forms, or vice versa, to ensure consistency.</p>
</li>
<li>
<p><strong>Normalization of Date and Time Formats:</strong>
    Converting various date and time representations into a standardized format, for example, transforming <code>September 1st, 2023</code> to <code>2023-09-01</code>.</p>
</li>
</ol>
<h2 id="tokenization">Tokenization<a class="headerlink" href="#tokenization" title="Permanent link">&para;</a></h2>
<p>Tokenization is the process of breaking down a text into substrings, like words or tokens.
In English and many other languages, words are often separated by spaces, making space a common delimiter.</p>
<p>We could use a simple regex to perform tokenization:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;The quick brown fox jumps over the lazy dog.&quot;</span>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="n">txt</span><span class="p">)</span>
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="p">[</span><span class="s1">&#39;The&#39;</span><span class="p">,</span> <span class="s1">&#39;quick&#39;</span><span class="p">,</span> <span class="s1">&#39;brown&#39;</span><span class="p">,</span> <span class="s1">&#39;fox&#39;</span><span class="p">,</span> <span class="s1">&#39;jumps&#39;</span><span class="p">,</span> <span class="s1">&#39;over&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;lazy&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">]</span>
</code></pre></div>
<p>But a simple regex might not always be sufficient in practice.
Consider the following example:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;Hello, world. This, is a test.&quot;</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="n">txt</span><span class="p">)</span>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="p">[</span><span class="s1">&#39;Hello,&#39;</span><span class="p">,</span> <span class="s1">&#39;world.&#39;</span><span class="p">,</span> <span class="s1">&#39;This,&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;test.&#39;</span><span class="p">]</span>
</code></pre></div>
<p>Usually, we also want to have the punctuation marks separated from the words, so a simple whitespace split is not sufficient anymore, and the regex will become more complex:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;([,.]|\s)&#39;</span><span class="p">,</span> <span class="n">txt</span><span class="p">)</span>
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="p">[</span><span class="s1">&#39;Hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;This&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]</span>
</code></pre></div>
<p>Like this, the task of tokenization can become quite complex, and it's better to use dedicated libraries like <a href="https://www.nltk.org/">NLTK</a> or <a href="https://spacy.io/">spaCy</a> for tokenization.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">word_tokenize</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;The quick brown fox jumps over the lazy dog.&quot;</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="p">[</span><span class="s1">&#39;The&#39;</span><span class="p">,</span> <span class="s1">&#39;quick&#39;</span><span class="p">,</span> <span class="s1">&#39;brown&#39;</span><span class="p">,</span> <span class="s1">&#39;fox&#39;</span><span class="p">,</span> <span class="s1">&#39;jumps&#39;</span><span class="p">,</span> <span class="s1">&#39;over&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;lazy&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">]</span>
</code></pre></div>
<p>You can also tokenize at the level of sentences using the sentence tokenizer:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">sent_tokenize</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;Salvatore has the best pizza in town. You should try the Calabrese. It&#39;s my favorite.&quot;</span>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="p">[</span><span class="s1">&#39;Salvatore has the best pizza in town.&#39;</span><span class="p">,</span> <span class="s1">&#39;You should try the Calabrese.&#39;</span><span class="p">,</span> <span class="s2">&quot;It&#39;s my favorite.&quot;</span><span class="p">]</span>
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Which tokenizer to use can be a crucial decision for your <abbr title="Natural Language Processing">NLP</abbr> project.
The code example above uses NLTK's <a href="https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize">default word tokenizer</a>, but others are available.
Please consider the <a href="https://www.nltk.org/api/nltk.tokenize.html#submodules">API reference</a> of NLTK's tokenize module for more information.</p>
</div>
<p>The following sections show some more sophisticated tokenization techniques.</p>
<h3 id="stopword-removal">Stopword removal<a class="headerlink" href="#stopword-removal" title="Permanent link">&para;</a></h3>
<p>Stopwords are common words (such as "and," "the," "is," etc.) that don't carry significant meaning in a text.
Stopword removal involves filtering out these words from a text to reduce noise and save processing time.
The goal is to focus on the more meaningful content words that contribute to the overall context of the text.</p>
<!-- TODO EXAM -->
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">word_tokenize</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.corpus</span><span class="w"> </span><span class="kn">import</span> <span class="n">stopwords</span>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;Early morning walks provide fresh air and energy for the day.&quot;</span>
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)]</span>
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="p">[</span><span class="s1">&#39;Early&#39;</span><span class="p">,</span> <span class="s1">&#39;morning&#39;</span><span class="p">,</span> <span class="s1">&#39;walks&#39;</span><span class="p">,</span> <span class="s1">&#39;provide&#39;</span><span class="p">,</span> <span class="s1">&#39;fresh&#39;</span><span class="p">,</span> <span class="s1">&#39;air&#39;</span><span class="p">,</span> <span class="s1">&#39;energy&#39;</span><span class="p">,</span> <span class="s1">&#39;day&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">]</span>
</code></pre></div>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>In the era of LLMs, would you say it is still a good idea to remove stopwords?</p>
</div>
<h3 id="stemming">Stemming<a class="headerlink" href="#stemming" title="Permanent link">&para;</a></h3>
<p>Stemming is a process of reducing words to their base or root form by removing suffixes or prefixes.
The resulting stem might <strong>not always be a valid word</strong>, but it's intended to capture the core meaning of the word.
Some popular stemming algorithms include the Porter stemming algorithm and the Snowball stemmer.
Stemming can be computationally faster than lemmatization since it involves simpler rule-based manipulations.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.stem</span><span class="w"> </span><span class="kn">import</span> <span class="n">PorterStemmer</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;happily&quot;</span><span class="p">,</span> <span class="s2">&quot;flies&quot;</span><span class="p">,</span> <span class="s2">&quot;feet&quot;</span><span class="p">,</span> <span class="s2">&quot;denied&quot;</span><span class="p">,</span> <span class="s2">&quot;sensational&quot;</span><span class="p">,</span> <span class="s2">&quot;airliner&quot;</span><span class="p">,</span> <span class="s2">&quot;cats&quot;</span><span class="p">,</span> <span class="s2">&quot;houses&quot;</span><span class="p">,</span> <span class="s2">&quot;agreed&quot;</span><span class="p">,</span> <span class="s2">&quot;better&quot;</span><span class="p">]</span>
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="p">[</span><span class="s1">&#39;happili&#39;</span><span class="p">,</span> <span class="s1">&#39;fli&#39;</span><span class="p">,</span> <span class="s1">&#39;feet&#39;</span><span class="p">,</span> <span class="s1">&#39;deni&#39;</span><span class="p">,</span> <span class="s1">&#39;sensat&#39;</span><span class="p">,</span> <span class="s1">&#39;airlin&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;hous&#39;</span><span class="p">,</span> <span class="s1">&#39;agre&#39;</span><span class="p">,</span> <span class="s1">&#39;better&#39;</span><span class="p">]</span>
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Stemming algorithms use heuristic rules to perform these transformations, which can lead to over-stemming (reducing words too aggressively) or under-stemming (not reducing words enough).</p>
</div>
<h3 id="lemmatization">Lemmatization<a class="headerlink" href="#lemmatization" title="Permanent link">&para;</a></h3>
<p>Lemmatization is a more advanced technique that reduces words to their base form, known as the lemma.
Unlike stemming, lemmatization takes into account the word's morphological analysis and its <abbr title="part of speech">POS</abbr> to ensure that the resulting lemma is <strong>a valid word</strong> in the language.
This makes lemmatization more accurate but potentially slower than stemming.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">nltk.stem</span><span class="w"> </span><span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;happily&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;flies&quot;</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;feet&quot;</span><span class="p">,</span> <span class="s2">&quot;n&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;denied&quot;</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;sensational&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;airliner&quot;</span><span class="p">,</span> <span class="s2">&quot;n&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;cats&quot;</span><span class="p">,</span> <span class="s2">&quot;n&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;houses&quot;</span><span class="p">,</span> <span class="s2">&quot;n&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;agreed&quot;</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;better&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)]</span>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="o">*</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="p">[</span><span class="s1">&#39;happily&#39;</span><span class="p">,</span> <span class="s1">&#39;fly&#39;</span><span class="p">,</span> <span class="s1">&#39;foot&#39;</span><span class="p">,</span> <span class="s1">&#39;deny&#39;</span><span class="p">,</span> <span class="s1">&#39;sensational&#39;</span><span class="p">,</span> <span class="s1">&#39;airliner&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;agree&#39;</span><span class="p">,</span> <span class="s1">&#39;good&#39;</span><span class="p">]</span>
</code></pre></div>
<p>Lemmatization is often preferred in tasks where maintaining the grammaticality of the words is crucial, such as language generation or language understanding tasks.
It provides a cleaner and more linguistically accurate representation of words.</p>
<p>Stemming is faster but might result in less linguistically accurate roots, while lemmatization is more accurate but can be slower due to its linguistic analysis.
The choice between these techniques depends on the specific <abbr title="Natural Language Processing">NLP</abbr> task and the desired trade-off between speed and accuracy.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that we require the <abbr title="part of speech">POS</abbr> tag as a second argument for NLTK's <a href="https://www.nltk.org/api/nltk.stem.wordnet.html#nltk.stem.wordnet.WordNetLemmatizer.lemmatize"><code>WordNetLemmatizer</code></a>.
This is why we use the <a href="https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists">Python unpacking operator <code>*</code></a> here</p>
</div>
<h2 id="converting-tokens-into-embeddings">Converting tokens into embeddings<a class="headerlink" href="#converting-tokens-into-embeddings" title="Permanent link">&para;</a></h2>
<p>Now, letâ€™s convert these tokens from a Python string to an integer representation to produce the token IDs.
This conversion is an intermediate step before converting the token IDs into embedding vectors.<sup id="fnref3:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<p><img alt="Converting tokens into a vocabulary" src="https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/06.webp" title="Converting tokens into a vocabulary" width="80%" /></p>
<ul>
<li>We build a vocabulary by <strong>tokenizing</strong> the entire text in a training dataset into individual tokens.</li>
<li>These individual tokens are then <strong>sorted alphabetically</strong>, and duplicate tokens are removed.</li>
<li>The unique tokens are then aggregated into a <strong>vocabulary</strong> that defines a <strong>mapping</strong> from each unique token to a unique integer value.</li>
</ul>
<p>The next goal is to apply this vocabulary to convert <strong>new text into token IDs</strong>:<sup id="fnref4:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<p><img alt="Process of encoding tokens into token IDs" src="https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/07.webp" title="[Process of encoding tokens into token IDs" width="80%" /></p>
<ul>
<li>Starting with a new text sample, we <strong>tokenize</strong> the text and use the vocabulary to convert the text tokens into token IDs.</li>
<li>The <strong>vocabulary</strong> is built from the entire training set and can be applied to the training set itself and any new text samples.</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Encoding and Decoding</p>
<p>The process of converting tokens into token IDs is also known as <strong>encoding</strong>, while the reverse process of converting token IDs back into tokens is also known as <strong>decoding</strong>.<sup id="fnref6:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<p><img alt="Example of encoding and decoding" src="https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/08.webp" title="Example of encoding and decoding" width="80%" /></p>
</div>
<div class="admonition example">
<p class="admonition-title">Example</p>
<p>According to the illustration, the following <strong>sentence</strong>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>The quick fox.
</code></pre></div>
<p>would be tokenized into the following <strong>tokens</strong>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>[&quot;The&quot;, &quot;quick&quot;, &quot;fox&quot;]
</code></pre></div>
<p>and could be represented by the following <strong>token IDs</strong>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>[7, 6, 2]
</code></pre></div>
</div>
<h2 id="adding-special-context-tokens">Adding special context tokens<a class="headerlink" href="#adding-special-context-tokens" title="Permanent link">&para;</a></h2>
<p>To address the issue of unknown words or other edge cases, we can add special context tokens to the vocabulary.
These special tokens can be used to represent specific contexts or conditions that are not covered by the regular vocabulary tokens.
For example, these special tokens can include markers for unknown words or document boundaries.<sup id="fnref5:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<p><img alt="Adding special context tokens" src="https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/09.webp" title="Adding special context tokens" width="80%" /></p>
<ul>
<li>In this example, we add special tokens to a vocabulary to deal with certain contexts.</li>
<li>For instance, we add an <code>&lt;|unk|&gt;</code> token to represent new and unknown words that were not part of the training data and thus not part of the existing vocabulary.</li>
<li>Furthermore, we add an <code>&lt;|endoftext|&gt;</code> token that we can use to separate two unrelated text sources. This helps a model to understand that although these text sources are concatenated for training, they are, in fact, unrelated.</li>
</ul>
<h2 id="key-takeaways">Key takeaways<a class="headerlink" href="#key-takeaways" title="Permanent link">&para;</a></h2>
<ul>
<li>In <strong>preprocessing</strong>, we convert raw input text into tokens, map them to IDs, and convert these IDs into embeddings.</li>
<li>The <abbr title="Natural Language Processing">NLP</abbr> <strong>pipeline</strong> is a systematic approach to solving <abbr title="Natural Language Processing">NLP</abbr> problems by breaking them down into <strong>distinct steps</strong>.</li>
<li>Many times, the success of an <abbr title="Natural Language Processing">NLP</abbr> project is determined already before the actual modeling step. <strong>Preprocessing</strong> and data acquisition play an important role, and <strong>in practice, much effort</strong> is spent on these steps.</li>
<li>When working with text data, we can apply a variety of <strong>text processing techniques</strong> to clean and normalize the text, including lowercasing, removing punctuation, and handling special characters.</li>
<li><strong>Tokenization</strong> is the process of breaking down text into tokens, which is essential for further processing and analysis.</li>
<li><strong>Encoding</strong> refers to the process of converting tokens into token IDs, while <strong>decoding</strong> refers to the reverse process of converting token IDs back into tokens.</li>
<li>We can add <strong>special context tokens</strong> to the vocabulary to address edge cases and unknown words that are not covered by the regular vocabulary tokens.</li>
</ul>
<!-- footnotes -->
<!-- markdownlint-disable MD041 -->
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Image adapted from Raschka, Sebastian. <em>Build a Large Language Model (From Scratch)</em>. Shelter Island, NY: Manning, 2024. <a href="https://www.manning.com/books/build-a-large-language-model-from-scratch">https://www.manning.com/books/build-a-large-language-model-from-scratch</a>.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:1" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:1" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:1" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>Vajjala, Sowmya, S.V. Bharathi, Bodhisattwa Majumder, Anuj Gupta, and Harshit Surana. <em>Practical Natural Language Processing: A Comprehensive Guide to Building Real-world <abbr title="Natural Language Processing">NLP</abbr> Systems</em>. Sebastopol, CA: O'Reilly Media, 2020. <a href="https://www.practicalnlp.ai/">https://www.practicalnlp.ai/</a>.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p><a href="https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html">https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html</a>&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:pascal.keilbach@htwg-konstanz.de" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/pkeilbach/htwg-practical-nlp" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.tooltips", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>